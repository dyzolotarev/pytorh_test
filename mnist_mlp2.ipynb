{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from utils import mnist2, plot_graphs\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.6.0  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "pin_memory = torch.cuda.is_available()\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = mnist2(batch_size=64, valid=10000, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, batchnorm=False, dropout=False, lr=1e-4, l2=0.):\n",
    "        super(Net, self).__init__()\n",
    "        w = 128 * 10\n",
    "        self.fc1 = nn.Linear(28*28, w)\n",
    "        self.fc2 = nn.Linear(w, w)\n",
    "        self.fc3 = nn.Linear(w, 10)\n",
    "        if batchnorm:\n",
    "            self.bn = nn.BatchNorm1d(w)\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.optim = optim.Adam(self.parameters(), lr=lr, weight_decay=l2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        if self.batchnorm:\n",
    "            x = self.bn(x)\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        if self.dropout:\n",
    "            x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, output, target, **kwargs):\n",
    "        self._loss = F.nll_loss(output, target, **kwargs)\n",
    "        return self._loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, models):\n",
    "    train_size = len(train_loader.sampler)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "#         data = data.to(device)\n",
    "#         target = target.to(device)\n",
    "        pin_memory = False\n",
    "        data, target = data.cuda(non_blocking=pin_memory), target.cuda(non_blocking=pin_memory)\n",
    "    \n",
    "        for k, model in models.items():\n",
    "            model.optim.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = model.loss(output, target)\n",
    "            loss.backward()\n",
    "            model.optim.step()\n",
    "            \n",
    "        if batch_idx % 200 == 0:\n",
    "            line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "                epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "            losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "            print(line + losses)\n",
    "            \n",
    "    else:\n",
    "        batch_idx += 1\n",
    "        line = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLosses '.format(\n",
    "            epoch, batch_idx * len(data), train_size, 100. * batch_idx / len(train_loader))\n",
    "        losses = ' '.join(['{}: {:.6f}'.format(k, m._loss.item()) for k, m in models.items()])\n",
    "        print(line + losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'default': Net(False, False).to(device), 'bn': Net(True, False).to(device), 'drop': Net(False, True).to(device), 'both': Net(True, True).to(device)}\n",
    "train_log = {k: [] for k in models}\n",
    "test_log = {k: [] for k in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, loader, log=None):\n",
    "    test_size = len(loader.sampler)\n",
    "    avg_lambda = lambda l: 'Loss: {:.4f}'.format(l)\n",
    "    acc_lambda = lambda c, p: 'Accuracy: {}/{} ({:.0f}%)'.format(c, test_size, p)\n",
    "    line = lambda i, l, c, p: '{}: '.format(i) + avg_lambda(l) + '\\t' + acc_lambda(c, p)\n",
    "\n",
    "    test_loss = {k: 0. for k in models}\n",
    "    correct = {k: 0. for k in models}\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            # output = {k: m(data) for m in models}\n",
    "#             data = data.to(device)\n",
    "#             target = target.to(device)\n",
    "            data, target = data.cuda(non_blocking=pin_memory), target.cuda(non_blocking=pin_memory)\n",
    "        \n",
    "            for k, m in models.items():\n",
    "                output = m(data)\n",
    "                test_loss[k] += m.loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "                pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "                correct[k] += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "    \n",
    "    for k in models:\n",
    "        test_loss[k] /= test_size\n",
    "    correct_pct = {k: 100. * correct[k] / test_size for k in correct}\n",
    "    lines = '\\n'.join([line(k, test_loss[k], correct[k], correct_pct[k]) for k in models]) + '\\n'\n",
    "    report = 'Test set:\\n' + lines\n",
    "    if log is not None:\n",
    "        for k in models:\n",
    "            log[k].append((test_loss[k], correct_pct[k]))\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLosses default: 2.303749 bn: 2.322037 drop: 2.319606 both: 2.417658\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLosses default: 0.390970 bn: 0.441010 drop: 0.407020 both: 0.482237\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLosses default: 0.400083 bn: 0.312547 drop: 0.413433 both: 0.382156\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLosses default: 0.269310 bn: 0.186368 drop: 0.288064 both: 0.207117\n",
      "Train Epoch: 1 [12512/50000 (100%)]\tLosses default: 0.257826 bn: 0.095056 drop: 0.274531 both: 0.183830\n",
      "Test set:\n",
      "default: Loss: 0.2249\tAccuracy: 9338.0/10000 (93%)\n",
      "bn: Loss: 0.1405\tAccuracy: 9621.0/10000 (96%)\n",
      "drop: Loss: 0.2473\tAccuracy: 9272.0/10000 (93%)\n",
      "both: Loss: 0.1691\tAccuracy: 9538.0/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLosses default: 0.315628 bn: 0.187713 drop: 0.360515 both: 0.250673\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLosses default: 0.105928 bn: 0.068206 drop: 0.120999 both: 0.076671\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLosses default: 0.097638 bn: 0.049807 drop: 0.124394 both: 0.053839\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLosses default: 0.126308 bn: 0.047491 drop: 0.130544 both: 0.086323\n",
      "Train Epoch: 2 [12512/50000 (100%)]\tLosses default: 0.209627 bn: 0.206880 drop: 0.223185 both: 0.127613\n",
      "Test set:\n",
      "default: Loss: 0.1561\tAccuracy: 9537.0/10000 (95%)\n",
      "bn: Loss: 0.0916\tAccuracy: 9726.0/10000 (97%)\n",
      "drop: Loss: 0.1810\tAccuracy: 9472.0/10000 (95%)\n",
      "both: Loss: 0.1081\tAccuracy: 9674.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLosses default: 0.213010 bn: 0.112174 drop: 0.225207 both: 0.140621\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLosses default: 0.111153 bn: 0.022324 drop: 0.135586 both: 0.054750\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLosses default: 0.079275 bn: 0.032626 drop: 0.112724 both: 0.059180\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLosses default: 0.081630 bn: 0.063871 drop: 0.091219 both: 0.055022\n",
      "Train Epoch: 3 [12512/50000 (100%)]\tLosses default: 0.137729 bn: 0.173497 drop: 0.163772 both: 0.229136\n",
      "Test set:\n",
      "default: Loss: 0.1290\tAccuracy: 9613.0/10000 (96%)\n",
      "bn: Loss: 0.0805\tAccuracy: 9754.0/10000 (98%)\n",
      "drop: Loss: 0.1510\tAccuracy: 9543.0/10000 (95%)\n",
      "both: Loss: 0.0900\tAccuracy: 9719.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLosses default: 0.281882 bn: 0.098474 drop: 0.286769 both: 0.146260\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLosses default: 0.081314 bn: 0.070110 drop: 0.112168 both: 0.102776\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLosses default: 0.038367 bn: 0.010370 drop: 0.070914 both: 0.018651\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLosses default: 0.016580 bn: 0.005745 drop: 0.025257 both: 0.016120\n",
      "Train Epoch: 4 [12512/50000 (100%)]\tLosses default: 0.050956 bn: 0.046515 drop: 0.070259 both: 0.049122\n",
      "Test set:\n",
      "default: Loss: 0.1040\tAccuracy: 9677.0/10000 (97%)\n",
      "bn: Loss: 0.0723\tAccuracy: 9763.0/10000 (98%)\n",
      "drop: Loss: 0.1242\tAccuracy: 9634.0/10000 (96%)\n",
      "both: Loss: 0.0805\tAccuracy: 9734.0/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLosses default: 0.085301 bn: 0.042658 drop: 0.123602 both: 0.075449\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLosses default: 0.130666 bn: 0.065320 drop: 0.155430 both: 0.083193\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLosses default: 0.041793 bn: 0.020047 drop: 0.039860 both: 0.017764\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLosses default: 0.092443 bn: 0.034323 drop: 0.102873 both: 0.037779\n",
      "Train Epoch: 5 [12512/50000 (100%)]\tLosses default: 0.017687 bn: 0.002358 drop: 0.054130 both: 0.027097\n",
      "Test set:\n",
      "default: Loss: 0.0917\tAccuracy: 9711.0/10000 (97%)\n",
      "bn: Loss: 0.0683\tAccuracy: 9797.0/10000 (98%)\n",
      "drop: Loss: 0.1112\tAccuracy: 9665.0/10000 (97%)\n",
      "both: Loss: 0.0706\tAccuracy: 9800.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLosses default: 0.035192 bn: 0.030349 drop: 0.049894 both: 0.018709\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLosses default: 0.026365 bn: 0.014610 drop: 0.054942 both: 0.020643\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLosses default: 0.071281 bn: 0.023365 drop: 0.097375 both: 0.027942\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLosses default: 0.094496 bn: 0.112167 drop: 0.137974 both: 0.112960\n",
      "Train Epoch: 6 [12512/50000 (100%)]\tLosses default: 0.008172 bn: 0.014584 drop: 0.015855 both: 0.007879\n",
      "Test set:\n",
      "default: Loss: 0.0841\tAccuracy: 9746.0/10000 (97%)\n",
      "bn: Loss: 0.0733\tAccuracy: 9778.0/10000 (98%)\n",
      "drop: Loss: 0.0984\tAccuracy: 9707.0/10000 (97%)\n",
      "both: Loss: 0.0709\tAccuracy: 9782.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLosses default: 0.006809 bn: 0.002737 drop: 0.013675 both: 0.004014\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLosses default: 0.015291 bn: 0.010729 drop: 0.020689 both: 0.009248\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLosses default: 0.009500 bn: 0.002482 drop: 0.015793 both: 0.002017\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLosses default: 0.059018 bn: 0.025995 drop: 0.096822 both: 0.049545\n",
      "Train Epoch: 7 [12512/50000 (100%)]\tLosses default: 0.004357 bn: 0.008775 drop: 0.017143 both: 0.012647\n",
      "Test set:\n",
      "default: Loss: 0.0846\tAccuracy: 9738.0/10000 (97%)\n",
      "bn: Loss: 0.0711\tAccuracy: 9785.0/10000 (98%)\n",
      "drop: Loss: 0.0942\tAccuracy: 9702.0/10000 (97%)\n",
      "both: Loss: 0.0757\tAccuracy: 9780.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLosses default: 0.057276 bn: 0.004858 drop: 0.094960 both: 0.017098\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLosses default: 0.049916 bn: 0.007695 drop: 0.036787 both: 0.022593\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLosses default: 0.048000 bn: 0.006962 drop: 0.046772 both: 0.006192\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLosses default: 0.003284 bn: 0.000517 drop: 0.007751 both: 0.000868\n",
      "Train Epoch: 8 [12512/50000 (100%)]\tLosses default: 0.018822 bn: 0.010424 drop: 0.020713 both: 0.011222\n",
      "Test set:\n",
      "default: Loss: 0.0824\tAccuracy: 9757.0/10000 (98%)\n",
      "bn: Loss: 0.0709\tAccuracy: 9803.0/10000 (98%)\n",
      "drop: Loss: 0.0902\tAccuracy: 9725.0/10000 (97%)\n",
      "both: Loss: 0.0674\tAccuracy: 9804.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLosses default: 0.014823 bn: 0.003818 drop: 0.027251 both: 0.029654\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLosses default: 0.050204 bn: 0.011443 drop: 0.055957 both: 0.007235\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLosses default: 0.056120 bn: 0.028095 drop: 0.117359 both: 0.084918\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLosses default: 0.079761 bn: 0.051334 drop: 0.162116 both: 0.041831\n",
      "Train Epoch: 9 [12512/50000 (100%)]\tLosses default: 0.000782 bn: 0.000991 drop: 0.001220 both: 0.001368\n",
      "Test set:\n",
      "default: Loss: 0.0711\tAccuracy: 9783.0/10000 (98%)\n",
      "bn: Loss: 0.0793\tAccuracy: 9798.0/10000 (98%)\n",
      "drop: Loss: 0.0812\tAccuracy: 9744.0/10000 (97%)\n",
      "both: Loss: 0.0755\tAccuracy: 9805.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLosses default: 0.027844 bn: 0.043637 drop: 0.068210 both: 0.024761\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLosses default: 0.048846 bn: 0.012395 drop: 0.092860 both: 0.048795\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLosses default: 0.034913 bn: 0.003935 drop: 0.026234 both: 0.009299\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLosses default: 0.005009 bn: 0.004335 drop: 0.015650 both: 0.011232\n",
      "Train Epoch: 10 [12512/50000 (100%)]\tLosses default: 0.012868 bn: 0.001291 drop: 0.009415 both: 0.001192\n",
      "Test set:\n",
      "default: Loss: 0.0750\tAccuracy: 9781.0/10000 (98%)\n",
      "bn: Loss: 0.0733\tAccuracy: 9821.0/10000 (98%)\n",
      "drop: Loss: 0.0768\tAccuracy: 9769.0/10000 (98%)\n",
      "both: Loss: 0.0741\tAccuracy: 9811.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLosses default: 0.041166 bn: 0.023349 drop: 0.051625 both: 0.031303\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLosses default: 0.001935 bn: 0.001464 drop: 0.008328 both: 0.015857\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLosses default: 0.043128 bn: 0.002411 drop: 0.063064 both: 0.009503\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLosses default: 0.013195 bn: 0.025056 drop: 0.029003 both: 0.051809\n",
      "Train Epoch: 11 [12512/50000 (100%)]\tLosses default: 0.070421 bn: 0.056455 drop: 0.013439 both: 0.040060\n",
      "Test set:\n",
      "default: Loss: 0.0782\tAccuracy: 9775.0/10000 (98%)\n",
      "bn: Loss: 0.0768\tAccuracy: 9790.0/10000 (98%)\n",
      "drop: Loss: 0.0803\tAccuracy: 9762.0/10000 (98%)\n",
      "both: Loss: 0.0765\tAccuracy: 9806.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLosses default: 0.011453 bn: 0.063392 drop: 0.011116 both: 0.001619\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLosses default: 0.006204 bn: 0.035229 drop: 0.030693 both: 0.023781\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLosses default: 0.011693 bn: 0.013097 drop: 0.028511 both: 0.005587\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLosses default: 0.031132 bn: 0.001092 drop: 0.036814 both: 0.002843\n",
      "Train Epoch: 12 [12512/50000 (100%)]\tLosses default: 0.000730 bn: 0.007762 drop: 0.001401 both: 0.016732\n",
      "Test set:\n",
      "default: Loss: 0.0741\tAccuracy: 9795.0/10000 (98%)\n",
      "bn: Loss: 0.0788\tAccuracy: 9801.0/10000 (98%)\n",
      "drop: Loss: 0.0778\tAccuracy: 9763.0/10000 (98%)\n",
      "both: Loss: 0.0765\tAccuracy: 9800.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLosses default: 0.046241 bn: 0.041174 drop: 0.044199 both: 0.004783\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLosses default: 0.003122 bn: 0.001494 drop: 0.006415 both: 0.002858\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLosses default: 0.012233 bn: 0.001375 drop: 0.016839 both: 0.002533\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLosses default: 0.002560 bn: 0.001412 drop: 0.016168 both: 0.005304\n",
      "Train Epoch: 13 [12512/50000 (100%)]\tLosses default: 0.015146 bn: 0.006032 drop: 0.003489 both: 0.001335\n",
      "Test set:\n",
      "default: Loss: 0.0788\tAccuracy: 9790.0/10000 (98%)\n",
      "bn: Loss: 0.0755\tAccuracy: 9813.0/10000 (98%)\n",
      "drop: Loss: 0.0783\tAccuracy: 9787.0/10000 (98%)\n",
      "both: Loss: 0.0800\tAccuracy: 9806.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLosses default: 0.001623 bn: 0.000740 drop: 0.007922 both: 0.002013\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLosses default: 0.003298 bn: 0.000137 drop: 0.011870 both: 0.000147\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLosses default: 0.001341 bn: 0.000168 drop: 0.015212 both: 0.000461\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLosses default: 0.000892 bn: 0.001123 drop: 0.003810 both: 0.001906\n",
      "Train Epoch: 14 [12512/50000 (100%)]\tLosses default: 0.002521 bn: 0.001016 drop: 0.073707 both: 0.002225\n",
      "Test set:\n",
      "default: Loss: 0.0751\tAccuracy: 9788.0/10000 (98%)\n",
      "bn: Loss: 0.0758\tAccuracy: 9802.0/10000 (98%)\n",
      "drop: Loss: 0.0769\tAccuracy: 9773.0/10000 (98%)\n",
      "both: Loss: 0.0835\tAccuracy: 9804.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLosses default: 0.001684 bn: 0.000110 drop: 0.003482 both: 0.008756\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLosses default: 0.002437 bn: 0.000116 drop: 0.002856 both: 0.000315\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLosses default: 0.003707 bn: 0.023479 drop: 0.008547 both: 0.018036\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLosses default: 0.014943 bn: 0.020256 drop: 0.010953 both: 0.017784\n",
      "Train Epoch: 15 [12512/50000 (100%)]\tLosses default: 0.093765 bn: 0.015094 drop: 0.048133 both: 0.043686\n",
      "Test set:\n",
      "default: Loss: 0.0833\tAccuracy: 9781.0/10000 (98%)\n",
      "bn: Loss: 0.0772\tAccuracy: 9804.0/10000 (98%)\n",
      "drop: Loss: 0.0921\tAccuracy: 9756.0/10000 (98%)\n",
      "both: Loss: 0.0824\tAccuracy: 9803.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLosses default: 0.002950 bn: 0.005552 drop: 0.025994 both: 0.012650\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLosses default: 0.000665 bn: 0.000173 drop: 0.000427 both: 0.000047\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLosses default: 0.002030 bn: 0.011229 drop: 0.003172 both: 0.002325\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLosses default: 0.003352 bn: 0.000218 drop: 0.000982 both: 0.001158\n",
      "Train Epoch: 16 [12512/50000 (100%)]\tLosses default: 0.005854 bn: 0.000325 drop: 0.002953 both: 0.133246\n",
      "Test set:\n",
      "default: Loss: 0.0760\tAccuracy: 9803.0/10000 (98%)\n",
      "bn: Loss: 0.0750\tAccuracy: 9823.0/10000 (98%)\n",
      "drop: Loss: 0.0867\tAccuracy: 9771.0/10000 (98%)\n",
      "both: Loss: 0.0827\tAccuracy: 9820.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLosses default: 0.002200 bn: 0.036597 drop: 0.005291 both: 0.049629\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLosses default: 0.004386 bn: 0.059561 drop: 0.001889 both: 0.019610\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLosses default: 0.000085 bn: 0.001287 drop: 0.000530 both: 0.000166\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLosses default: 0.000129 bn: 0.000234 drop: 0.006193 both: 0.001872\n",
      "Train Epoch: 17 [12512/50000 (100%)]\tLosses default: 0.005281 bn: 0.009494 drop: 0.073804 both: 0.095089\n",
      "Test set:\n",
      "default: Loss: 0.0769\tAccuracy: 9809.0/10000 (98%)\n",
      "bn: Loss: 0.0800\tAccuracy: 9806.0/10000 (98%)\n",
      "drop: Loss: 0.0838\tAccuracy: 9778.0/10000 (98%)\n",
      "both: Loss: 0.0823\tAccuracy: 9798.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLosses default: 0.001322 bn: 0.002447 drop: 0.024366 both: 0.000643\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLosses default: 0.000070 bn: 0.000064 drop: 0.000249 both: 0.000268\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLosses default: 0.000632 bn: 0.005943 drop: 0.001253 both: 0.001122\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLosses default: 0.000255 bn: 0.001413 drop: 0.000682 both: 0.000323\n",
      "Train Epoch: 18 [12512/50000 (100%)]\tLosses default: 0.005767 bn: 0.000292 drop: 0.016030 both: 0.002680\n",
      "Test set:\n",
      "default: Loss: 0.0753\tAccuracy: 9828.0/10000 (98%)\n",
      "bn: Loss: 0.0884\tAccuracy: 9783.0/10000 (98%)\n",
      "drop: Loss: 0.0840\tAccuracy: 9801.0/10000 (98%)\n",
      "both: Loss: 0.0806\tAccuracy: 9797.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLosses default: 0.001901 bn: 0.001013 drop: 0.016556 both: 0.000469\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLosses default: 0.000409 bn: 0.001609 drop: 0.001982 both: 0.000186\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLosses default: 0.000155 bn: 0.000059 drop: 0.000189 both: 0.000079\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLosses default: 0.015041 bn: 0.000740 drop: 0.002817 both: 0.000858\n",
      "Train Epoch: 19 [12512/50000 (100%)]\tLosses default: 0.001541 bn: 0.013030 drop: 0.000432 both: 0.266405\n",
      "Test set:\n",
      "default: Loss: 0.0914\tAccuracy: 9789.0/10000 (98%)\n",
      "bn: Loss: 0.0786\tAccuracy: 9812.0/10000 (98%)\n",
      "drop: Loss: 0.0913\tAccuracy: 9769.0/10000 (98%)\n",
      "both: Loss: 0.0873\tAccuracy: 9809.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLosses default: 0.000822 bn: 0.000078 drop: 0.004085 both: 0.000594\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLosses default: 0.000353 bn: 0.000369 drop: 0.000509 both: 0.001410\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLosses default: 0.001199 bn: 0.018318 drop: 0.000527 both: 0.000235\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLosses default: 0.000240 bn: 0.001398 drop: 0.001922 both: 0.000163\n",
      "Train Epoch: 20 [12512/50000 (100%)]\tLosses default: 0.000661 bn: 0.000033 drop: 0.000233 both: 0.000034\n",
      "Test set:\n",
      "default: Loss: 0.0844\tAccuracy: 9804.0/10000 (98%)\n",
      "bn: Loss: 0.0829\tAccuracy: 9812.0/10000 (98%)\n",
      "drop: Loss: 0.0792\tAccuracy: 9802.0/10000 (98%)\n",
      "both: Loss: 0.0869\tAccuracy: 9806.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLosses default: 0.002735 bn: 0.000778 drop: 0.019997 both: 0.000144\n",
      "Train Epoch: 21 [12800/50000 (26%)]\tLosses default: 0.000360 bn: 0.008656 drop: 0.004758 both: 0.020321\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLosses default: 0.000105 bn: 0.000204 drop: 0.002836 both: 0.000095\n",
      "Train Epoch: 21 [38400/50000 (77%)]\tLosses default: 0.000940 bn: 0.001442 drop: 0.002507 both: 0.000604\n",
      "Train Epoch: 21 [12512/50000 (100%)]\tLosses default: 0.000909 bn: 0.000301 drop: 0.004091 both: 0.000767\n",
      "Test set:\n",
      "default: Loss: 0.1090\tAccuracy: 9744.0/10000 (97%)\n",
      "bn: Loss: 0.0732\tAccuracy: 9825.0/10000 (98%)\n",
      "drop: Loss: 0.0856\tAccuracy: 9795.0/10000 (98%)\n",
      "both: Loss: 0.0818\tAccuracy: 9824.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLosses default: 0.017766 bn: 0.000059 drop: 0.000633 both: 0.000362\n",
      "Train Epoch: 22 [12800/50000 (26%)]\tLosses default: 0.003499 bn: 0.003829 drop: 0.026588 both: 0.014248\n",
      "Train Epoch: 22 [25600/50000 (51%)]\tLosses default: 0.000091 bn: 0.008791 drop: 0.006553 both: 0.000088\n",
      "Train Epoch: 22 [38400/50000 (77%)]\tLosses default: 0.005017 bn: 0.005032 drop: 0.001137 both: 0.001023\n",
      "Train Epoch: 22 [12512/50000 (100%)]\tLosses default: 0.028956 bn: 0.000650 drop: 0.039953 both: 0.077492\n",
      "Test set:\n",
      "default: Loss: 0.0838\tAccuracy: 9815.0/10000 (98%)\n",
      "bn: Loss: 0.0785\tAccuracy: 9815.0/10000 (98%)\n",
      "drop: Loss: 0.0881\tAccuracy: 9797.0/10000 (98%)\n",
      "both: Loss: 0.0890\tAccuracy: 9802.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLosses default: 0.001880 bn: 0.000867 drop: 0.000339 both: 0.003621\n",
      "Train Epoch: 23 [12800/50000 (26%)]\tLosses default: 0.000710 bn: 0.000027 drop: 0.000463 both: 0.000178\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLosses default: 0.000317 bn: 0.000089 drop: 0.012292 both: 0.000595\n",
      "Train Epoch: 23 [38400/50000 (77%)]\tLosses default: 0.003808 bn: 0.000387 drop: 0.009630 both: 0.000890\n",
      "Train Epoch: 23 [12512/50000 (100%)]\tLosses default: 0.000201 bn: 0.005019 drop: 0.000215 both: 0.014851\n",
      "Test set:\n",
      "default: Loss: 0.0818\tAccuracy: 9829.0/10000 (98%)\n",
      "bn: Loss: 0.0734\tAccuracy: 9828.0/10000 (98%)\n",
      "drop: Loss: 0.0943\tAccuracy: 9788.0/10000 (98%)\n",
      "both: Loss: 0.0854\tAccuracy: 9806.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLosses default: 0.000224 bn: 0.000076 drop: 0.006238 both: 0.003660\n",
      "Train Epoch: 24 [12800/50000 (26%)]\tLosses default: 0.000312 bn: 0.000322 drop: 0.012988 both: 0.003061\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLosses default: 0.042684 bn: 0.000450 drop: 0.011788 both: 0.002341\n",
      "Train Epoch: 24 [38400/50000 (77%)]\tLosses default: 0.000055 bn: 0.000024 drop: 0.000146 both: 0.000118\n",
      "Train Epoch: 24 [12512/50000 (100%)]\tLosses default: 0.001958 bn: 0.003873 drop: 0.014852 both: 0.008415\n",
      "Test set:\n",
      "default: Loss: 0.1124\tAccuracy: 9753.0/10000 (98%)\n",
      "bn: Loss: 0.0786\tAccuracy: 9830.0/10000 (98%)\n",
      "drop: Loss: 0.0841\tAccuracy: 9803.0/10000 (98%)\n",
      "both: Loss: 0.0840\tAccuracy: 9811.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLosses default: 0.021614 bn: 0.000658 drop: 0.001702 both: 0.000079\n",
      "Train Epoch: 25 [12800/50000 (26%)]\tLosses default: 0.010545 bn: 0.002560 drop: 0.058654 both: 0.001255\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLosses default: 0.000778 bn: 0.009401 drop: 0.000123 both: 0.000328\n",
      "Train Epoch: 25 [38400/50000 (77%)]\tLosses default: 0.000237 bn: 0.000338 drop: 0.004472 both: 0.000008\n",
      "Train Epoch: 25 [12512/50000 (100%)]\tLosses default: 0.000600 bn: 0.002701 drop: 0.002324 both: 0.002921\n",
      "Test set:\n",
      "default: Loss: 0.0869\tAccuracy: 9818.0/10000 (98%)\n",
      "bn: Loss: 0.0795\tAccuracy: 9824.0/10000 (98%)\n",
      "drop: Loss: 0.0913\tAccuracy: 9793.0/10000 (98%)\n",
      "both: Loss: 0.0838\tAccuracy: 9821.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLosses default: 0.000846 bn: 0.000115 drop: 0.001361 both: 0.000174\n",
      "Train Epoch: 26 [12800/50000 (26%)]\tLosses default: 0.000912 bn: 0.000027 drop: 0.000435 both: 0.000373\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLosses default: 0.002952 bn: 0.000056 drop: 0.000819 both: 0.000085\n",
      "Train Epoch: 26 [38400/50000 (77%)]\tLosses default: 0.000340 bn: 0.000007 drop: 0.001904 both: 0.000054\n",
      "Train Epoch: 26 [12512/50000 (100%)]\tLosses default: 0.001588 bn: 0.000271 drop: 0.000020 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 0.0905\tAccuracy: 9797.0/10000 (98%)\n",
      "bn: Loss: 0.0790\tAccuracy: 9820.0/10000 (98%)\n",
      "drop: Loss: 0.1110\tAccuracy: 9761.0/10000 (98%)\n",
      "both: Loss: 0.0830\tAccuracy: 9817.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLosses default: 0.008578 bn: 0.000649 drop: 0.033529 both: 0.000885\n",
      "Train Epoch: 27 [12800/50000 (26%)]\tLosses default: 0.004013 bn: 0.000220 drop: 0.002599 both: 0.008661\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLosses default: 0.000339 bn: 0.000026 drop: 0.000337 both: 0.003259\n",
      "Train Epoch: 27 [38400/50000 (77%)]\tLosses default: 0.000581 bn: 0.005765 drop: 0.000062 both: 0.000300\n",
      "Train Epoch: 27 [12512/50000 (100%)]\tLosses default: 0.000015 bn: 0.000231 drop: 0.002050 both: 0.000982\n",
      "Test set:\n",
      "default: Loss: 0.0833\tAccuracy: 9829.0/10000 (98%)\n",
      "bn: Loss: 0.0921\tAccuracy: 9807.0/10000 (98%)\n",
      "drop: Loss: 0.1076\tAccuracy: 9756.0/10000 (98%)\n",
      "both: Loss: 0.1014\tAccuracy: 9792.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLosses default: 0.000165 bn: 0.000400 drop: 0.010984 both: 0.000269\n",
      "Train Epoch: 28 [12800/50000 (26%)]\tLosses default: 0.004327 bn: 0.000238 drop: 0.000197 both: 0.001598\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLosses default: 0.001145 bn: 0.009395 drop: 0.000606 both: 0.000108\n",
      "Train Epoch: 28 [38400/50000 (77%)]\tLosses default: 0.000277 bn: 0.000918 drop: 0.000175 both: 0.000841\n",
      "Train Epoch: 28 [12512/50000 (100%)]\tLosses default: 0.004229 bn: 0.001993 drop: 0.000346 both: 0.007610\n",
      "Test set:\n",
      "default: Loss: 0.0860\tAccuracy: 9825.0/10000 (98%)\n",
      "bn: Loss: 0.0824\tAccuracy: 9825.0/10000 (98%)\n",
      "drop: Loss: 0.1056\tAccuracy: 9777.0/10000 (98%)\n",
      "both: Loss: 0.0947\tAccuracy: 9815.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLosses default: 0.000321 bn: 0.000115 drop: 0.005795 both: 0.000141\n",
      "Train Epoch: 29 [12800/50000 (26%)]\tLosses default: 0.003429 bn: 0.000050 drop: 0.000076 both: 0.001123\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLosses default: 0.000140 bn: 0.000140 drop: 0.001391 both: 0.000377\n",
      "Train Epoch: 29 [38400/50000 (77%)]\tLosses default: 0.000292 bn: 0.001226 drop: 0.015672 both: 0.000106\n",
      "Train Epoch: 29 [12512/50000 (100%)]\tLosses default: 0.000028 bn: 0.000459 drop: 0.000582 both: 0.114474\n",
      "Test set:\n",
      "default: Loss: 0.0816\tAccuracy: 9826.0/10000 (98%)\n",
      "bn: Loss: 0.0862\tAccuracy: 9804.0/10000 (98%)\n",
      "drop: Loss: 0.0947\tAccuracy: 9794.0/10000 (98%)\n",
      "both: Loss: 0.1058\tAccuracy: 9800.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLosses default: 0.000032 bn: 0.010753 drop: 0.000063 both: 0.000799\n",
      "Train Epoch: 30 [12800/50000 (26%)]\tLosses default: 0.000102 bn: 0.000079 drop: 0.000199 both: 0.000388\n",
      "Train Epoch: 30 [25600/50000 (51%)]\tLosses default: 0.000962 bn: 0.000395 drop: 0.008126 both: 0.000262\n",
      "Train Epoch: 30 [38400/50000 (77%)]\tLosses default: 0.000008 bn: 0.000026 drop: 0.000178 both: 0.000014\n",
      "Train Epoch: 30 [12512/50000 (100%)]\tLosses default: 0.000004 bn: 0.000005 drop: 0.000000 both: 0.000005\n",
      "Test set:\n",
      "default: Loss: 0.0789\tAccuracy: 9832.0/10000 (98%)\n",
      "bn: Loss: 0.0806\tAccuracy: 9837.0/10000 (98%)\n",
      "drop: Loss: 0.0917\tAccuracy: 9811.0/10000 (98%)\n",
      "both: Loss: 0.0959\tAccuracy: 9799.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLosses default: 0.000072 bn: 0.000057 drop: 0.001854 both: 0.000062\n",
      "Train Epoch: 31 [12800/50000 (26%)]\tLosses default: 0.000105 bn: 0.000033 drop: 0.011983 both: 0.000026\n",
      "Train Epoch: 31 [25600/50000 (51%)]\tLosses default: 0.000038 bn: 0.002073 drop: 0.000111 both: 0.000068\n",
      "Train Epoch: 31 [38400/50000 (77%)]\tLosses default: 0.000294 bn: 0.000087 drop: 0.030626 both: 0.000034\n",
      "Train Epoch: 31 [12512/50000 (100%)]\tLosses default: 0.000095 bn: 0.006961 drop: 0.000133 both: 0.005342\n",
      "Test set:\n",
      "default: Loss: 0.0800\tAccuracy: 9830.0/10000 (98%)\n",
      "bn: Loss: 0.0787\tAccuracy: 9840.0/10000 (98%)\n",
      "drop: Loss: 0.0997\tAccuracy: 9779.0/10000 (98%)\n",
      "both: Loss: 0.0953\tAccuracy: 9808.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLosses default: 0.000048 bn: 0.000011 drop: 0.002337 both: 0.000014\n",
      "Train Epoch: 32 [12800/50000 (26%)]\tLosses default: 0.000045 bn: 0.000097 drop: 0.000101 both: 0.000465\n",
      "Train Epoch: 32 [25600/50000 (51%)]\tLosses default: 0.000089 bn: 0.000774 drop: 0.000185 both: 0.002006\n",
      "Train Epoch: 32 [38400/50000 (77%)]\tLosses default: 0.000040 bn: 0.000091 drop: 0.000157 both: 0.000567\n",
      "Train Epoch: 32 [12512/50000 (100%)]\tLosses default: 0.000060 bn: 0.000025 drop: 0.002481 both: 0.001903\n",
      "Test set:\n",
      "default: Loss: 0.0801\tAccuracy: 9833.0/10000 (98%)\n",
      "bn: Loss: 0.0898\tAccuracy: 9816.0/10000 (98%)\n",
      "drop: Loss: 0.1063\tAccuracy: 9783.0/10000 (98%)\n",
      "both: Loss: 0.0968\tAccuracy: 9806.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLosses default: 0.000056 bn: 0.000522 drop: 0.002511 both: 0.048959\n",
      "Train Epoch: 33 [12800/50000 (26%)]\tLosses default: 0.000168 bn: 0.003502 drop: 0.000597 both: 0.000090\n",
      "Train Epoch: 33 [25600/50000 (51%)]\tLosses default: 0.000160 bn: 0.006651 drop: 0.016572 both: 0.000763\n",
      "Train Epoch: 33 [38400/50000 (77%)]\tLosses default: 0.000021 bn: 0.000344 drop: 0.001796 both: 0.000057\n",
      "Train Epoch: 33 [12512/50000 (100%)]\tLosses default: 0.000175 bn: 0.012084 drop: 0.000167 both: 0.053856\n",
      "Test set:\n",
      "default: Loss: 0.0812\tAccuracy: 9830.0/10000 (98%)\n",
      "bn: Loss: 0.0871\tAccuracy: 9827.0/10000 (98%)\n",
      "drop: Loss: 0.0945\tAccuracy: 9798.0/10000 (98%)\n",
      "both: Loss: 0.0963\tAccuracy: 9802.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLosses default: 0.000119 bn: 0.000164 drop: 0.004716 both: 0.000556\n",
      "Train Epoch: 34 [12800/50000 (26%)]\tLosses default: 0.000019 bn: 0.000334 drop: 0.000242 both: 0.000005\n",
      "Train Epoch: 34 [25600/50000 (51%)]\tLosses default: 0.000013 bn: 0.000083 drop: 0.000341 both: 0.000862\n",
      "Train Epoch: 34 [38400/50000 (77%)]\tLosses default: 0.000071 bn: 0.000765 drop: 0.000111 both: 0.002002\n",
      "Train Epoch: 34 [12512/50000 (100%)]\tLosses default: 0.032528 bn: 0.000288 drop: 0.038563 both: 0.044327\n",
      "Test set:\n",
      "default: Loss: 0.1076\tAccuracy: 9792.0/10000 (98%)\n",
      "bn: Loss: 0.1012\tAccuracy: 9804.0/10000 (98%)\n",
      "drop: Loss: 0.1016\tAccuracy: 9785.0/10000 (98%)\n",
      "both: Loss: 0.1067\tAccuracy: 9818.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLosses default: 0.009705 bn: 0.000104 drop: 0.016048 both: 0.002075\n",
      "Train Epoch: 35 [12800/50000 (26%)]\tLosses default: 0.020322 bn: 0.000159 drop: 0.000080 both: 0.000137\n",
      "Train Epoch: 35 [25600/50000 (51%)]\tLosses default: 0.000137 bn: 0.000069 drop: 0.000047 both: 0.000049\n",
      "Train Epoch: 35 [38400/50000 (77%)]\tLosses default: 0.000255 bn: 0.001311 drop: 0.001610 both: 0.001754\n",
      "Train Epoch: 35 [12512/50000 (100%)]\tLosses default: 0.001300 bn: 0.000273 drop: 0.000036 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 0.0886\tAccuracy: 9812.0/10000 (98%)\n",
      "bn: Loss: 0.1091\tAccuracy: 9749.0/10000 (97%)\n",
      "drop: Loss: 0.0927\tAccuracy: 9809.0/10000 (98%)\n",
      "both: Loss: 0.0964\tAccuracy: 9829.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLosses default: 0.002288 bn: 0.003829 drop: 0.000724 both: 0.000026\n",
      "Train Epoch: 36 [12800/50000 (26%)]\tLosses default: 0.000311 bn: 0.000207 drop: 0.000145 both: 0.000731\n",
      "Train Epoch: 36 [25600/50000 (51%)]\tLosses default: 0.001078 bn: 0.002117 drop: 0.001677 both: 0.000363\n",
      "Train Epoch: 36 [38400/50000 (77%)]\tLosses default: 0.000013 bn: 0.000002 drop: 0.013310 both: 0.000170\n",
      "Train Epoch: 36 [12512/50000 (100%)]\tLosses default: 0.000295 bn: 0.009598 drop: 0.000817 both: 0.261745\n",
      "Test set:\n",
      "default: Loss: 0.0849\tAccuracy: 9828.0/10000 (98%)\n",
      "bn: Loss: 0.0726\tAccuracy: 9840.0/10000 (98%)\n",
      "drop: Loss: 0.0960\tAccuracy: 9803.0/10000 (98%)\n",
      "both: Loss: 0.1000\tAccuracy: 9802.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLosses default: 0.000111 bn: 0.000028 drop: 0.015742 both: 0.000025\n",
      "Train Epoch: 37 [12800/50000 (26%)]\tLosses default: 0.000118 bn: 0.000027 drop: 0.000049 both: 0.000230\n",
      "Train Epoch: 37 [25600/50000 (51%)]\tLosses default: 0.000182 bn: 0.000079 drop: 0.000952 both: 0.000128\n",
      "Train Epoch: 37 [38400/50000 (77%)]\tLosses default: 0.000113 bn: 0.000205 drop: 0.001414 both: 0.000476\n",
      "Train Epoch: 37 [12512/50000 (100%)]\tLosses default: 0.000052 bn: 0.000413 drop: 0.000928 both: 0.000048\n",
      "Test set:\n",
      "default: Loss: 0.0846\tAccuracy: 9832.0/10000 (98%)\n",
      "bn: Loss: 0.0805\tAccuracy: 9842.0/10000 (98%)\n",
      "drop: Loss: 0.1018\tAccuracy: 9789.0/10000 (98%)\n",
      "both: Loss: 0.0965\tAccuracy: 9814.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLosses default: 0.000051 bn: 0.000038 drop: 0.002426 both: 0.000759\n",
      "Train Epoch: 38 [12800/50000 (26%)]\tLosses default: 0.000101 bn: 0.000053 drop: 0.019548 both: 0.002171\n",
      "Train Epoch: 38 [25600/50000 (51%)]\tLosses default: 0.000132 bn: 0.000492 drop: 0.003415 both: 0.000084\n",
      "Train Epoch: 38 [38400/50000 (77%)]\tLosses default: 0.000018 bn: 0.000034 drop: 0.000068 both: 0.000082\n",
      "Train Epoch: 38 [12512/50000 (100%)]\tLosses default: 0.000068 bn: 0.003393 drop: 0.001456 both: 0.001852\n",
      "Test set:\n",
      "default: Loss: 0.0845\tAccuracy: 9834.0/10000 (98%)\n",
      "bn: Loss: 0.0806\tAccuracy: 9832.0/10000 (98%)\n",
      "drop: Loss: 0.1032\tAccuracy: 9786.0/10000 (98%)\n",
      "both: Loss: 0.0982\tAccuracy: 9817.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLosses default: 0.000053 bn: 0.000070 drop: 0.000553 both: 0.000006\n",
      "Train Epoch: 39 [12800/50000 (26%)]\tLosses default: 0.000058 bn: 0.000144 drop: 0.000643 both: 0.000479\n",
      "Train Epoch: 39 [25600/50000 (51%)]\tLosses default: 0.000021 bn: 0.000036 drop: 0.000019 both: 0.000044\n",
      "Train Epoch: 39 [38400/50000 (77%)]\tLosses default: 0.000063 bn: 0.003758 drop: 0.000616 both: 0.000398\n",
      "Train Epoch: 39 [12512/50000 (100%)]\tLosses default: 0.000159 bn: 0.115316 drop: 0.002201 both: 0.042593\n",
      "Test set:\n",
      "default: Loss: 0.0857\tAccuracy: 9831.0/10000 (98%)\n",
      "bn: Loss: 0.0819\tAccuracy: 9838.0/10000 (98%)\n",
      "drop: Loss: 0.1080\tAccuracy: 9777.0/10000 (98%)\n",
      "both: Loss: 0.1013\tAccuracy: 9797.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLosses default: 0.000057 bn: 0.007690 drop: 0.019089 both: 0.000272\n",
      "Train Epoch: 40 [12800/50000 (26%)]\tLosses default: 0.000044 bn: 0.000017 drop: 0.000047 both: 0.000426\n",
      "Train Epoch: 40 [25600/50000 (51%)]\tLosses default: 0.000063 bn: 0.000005 drop: 0.102845 both: 0.000020\n",
      "Train Epoch: 40 [38400/50000 (77%)]\tLosses default: 0.000099 bn: 0.001666 drop: 0.000096 both: 0.000101\n",
      "Train Epoch: 40 [12512/50000 (100%)]\tLosses default: 0.000010 bn: 0.000003 drop: 0.000047 both: 0.000032\n",
      "Test set:\n",
      "default: Loss: 0.0848\tAccuracy: 9836.0/10000 (98%)\n",
      "bn: Loss: 0.0963\tAccuracy: 9813.0/10000 (98%)\n",
      "drop: Loss: 0.0954\tAccuracy: 9797.0/10000 (98%)\n",
      "both: Loss: 0.1076\tAccuracy: 9817.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLosses default: 0.000064 bn: 0.000898 drop: 0.000091 both: 0.003107\n",
      "Train Epoch: 41 [12800/50000 (26%)]\tLosses default: 0.000029 bn: 0.000108 drop: 0.000336 both: 0.000073\n",
      "Train Epoch: 41 [25600/50000 (51%)]\tLosses default: 0.000026 bn: 0.000483 drop: 0.001234 both: 0.000010\n",
      "Train Epoch: 41 [38400/50000 (77%)]\tLosses default: 0.000024 bn: 0.000028 drop: 0.001945 both: 0.000017\n",
      "Train Epoch: 41 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.000960 drop: 0.000015 both: 0.007075\n",
      "Test set:\n",
      "default: Loss: 0.0857\tAccuracy: 9831.0/10000 (98%)\n",
      "bn: Loss: 0.0842\tAccuracy: 9833.0/10000 (98%)\n",
      "drop: Loss: 0.1024\tAccuracy: 9795.0/10000 (98%)\n",
      "both: Loss: 0.1073\tAccuracy: 9816.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 42 [0/50000 (0%)]\tLosses default: 0.000014 bn: 0.000249 drop: 0.000029 both: 0.002134\n",
      "Train Epoch: 42 [12800/50000 (26%)]\tLosses default: 0.000026 bn: 0.016872 drop: 0.000083 both: 0.000719\n",
      "Train Epoch: 42 [25600/50000 (51%)]\tLosses default: 0.000029 bn: 0.000033 drop: 0.000183 both: 0.000024\n",
      "Train Epoch: 42 [38400/50000 (77%)]\tLosses default: 0.000051 bn: 0.000130 drop: 0.000950 both: 0.001417\n",
      "Train Epoch: 42 [12512/50000 (100%)]\tLosses default: 0.000094 bn: 0.042399 drop: 0.014975 both: 0.004105\n",
      "Test set:\n",
      "default: Loss: 0.0866\tAccuracy: 9834.0/10000 (98%)\n",
      "bn: Loss: 0.0906\tAccuracy: 9822.0/10000 (98%)\n",
      "drop: Loss: 0.0993\tAccuracy: 9805.0/10000 (98%)\n",
      "both: Loss: 0.1103\tAccuracy: 9796.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLosses default: 0.000009 bn: 0.000017 drop: 0.000701 both: 0.000931\n",
      "Train Epoch: 43 [12800/50000 (26%)]\tLosses default: 0.000008 bn: 0.000209 drop: 0.000112 both: 0.000021\n",
      "Train Epoch: 43 [25600/50000 (51%)]\tLosses default: 0.000055 bn: 0.001705 drop: 0.000518 both: 0.000088\n",
      "Train Epoch: 43 [38400/50000 (77%)]\tLosses default: 0.000023 bn: 0.000032 drop: 0.000077 both: 0.000369\n",
      "Train Epoch: 43 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000000 both: 0.000000\n",
      "Test set:\n",
      "default: Loss: 0.0873\tAccuracy: 9837.0/10000 (98%)\n",
      "bn: Loss: 0.0850\tAccuracy: 9836.0/10000 (98%)\n",
      "drop: Loss: 0.0954\tAccuracy: 9813.0/10000 (98%)\n",
      "both: Loss: 0.1069\tAccuracy: 9797.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLosses default: 0.000012 bn: 0.000014 drop: 0.000016 both: 0.003727\n",
      "Train Epoch: 44 [12800/50000 (26%)]\tLosses default: 0.000004 bn: 0.000008 drop: 0.000032 both: 0.000054\n",
      "Train Epoch: 44 [25600/50000 (51%)]\tLosses default: 0.000005 bn: 0.000344 drop: 0.001839 both: 0.000015\n",
      "Train Epoch: 44 [38400/50000 (77%)]\tLosses default: 0.000056 bn: 0.000272 drop: 0.000226 both: 0.000213\n",
      "Train Epoch: 44 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.000012 drop: 0.005450 both: 0.014547\n",
      "Test set:\n",
      "default: Loss: 0.0895\tAccuracy: 9839.0/10000 (98%)\n",
      "bn: Loss: 0.0780\tAccuracy: 9849.0/10000 (98%)\n",
      "drop: Loss: 0.1042\tAccuracy: 9791.0/10000 (98%)\n",
      "both: Loss: 0.1109\tAccuracy: 9804.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLosses default: 0.000005 bn: 0.000499 drop: 0.000104 both: 0.000082\n",
      "Train Epoch: 45 [12800/50000 (26%)]\tLosses default: 0.000120 bn: 0.000558 drop: 0.104374 both: 0.002235\n",
      "Train Epoch: 45 [25600/50000 (51%)]\tLosses default: 0.000006 bn: 0.000007 drop: 0.000156 both: 0.000026\n",
      "Train Epoch: 45 [38400/50000 (77%)]\tLosses default: 0.000024 bn: 0.001379 drop: 0.002384 both: 0.000228\n",
      "Train Epoch: 45 [12512/50000 (100%)]\tLosses default: 0.000002 bn: 0.914704 drop: 0.000069 both: 0.588206\n",
      "Test set:\n",
      "default: Loss: 0.0903\tAccuracy: 9841.0/10000 (98%)\n",
      "bn: Loss: 0.0900\tAccuracy: 9824.0/10000 (98%)\n",
      "drop: Loss: 0.0977\tAccuracy: 9810.0/10000 (98%)\n",
      "both: Loss: 0.0990\tAccuracy: 9815.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLosses default: 0.000007 bn: 0.000011 drop: 0.000006 both: 0.000077\n",
      "Train Epoch: 46 [12800/50000 (26%)]\tLosses default: 0.000010 bn: 0.001139 drop: 0.041396 both: 0.000635\n",
      "Train Epoch: 46 [25600/50000 (51%)]\tLosses default: 0.000005 bn: 0.000484 drop: 0.000444 both: 0.000030\n",
      "Train Epoch: 46 [38400/50000 (77%)]\tLosses default: 0.000374 bn: 0.000080 drop: 0.000119 both: 0.000014\n",
      "Train Epoch: 46 [12512/50000 (100%)]\tLosses default: 0.000314 bn: 0.020512 drop: 0.000306 both: 0.001823\n",
      "Test set:\n",
      "default: Loss: 0.1032\tAccuracy: 9802.0/10000 (98%)\n",
      "bn: Loss: 0.0846\tAccuracy: 9830.0/10000 (98%)\n",
      "drop: Loss: 0.0987\tAccuracy: 9799.0/10000 (98%)\n",
      "both: Loss: 0.1113\tAccuracy: 9805.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLosses default: 0.000668 bn: 0.000351 drop: 0.000161 both: 0.000028\n",
      "Train Epoch: 47 [12800/50000 (26%)]\tLosses default: 0.007469 bn: 0.000346 drop: 0.000837 both: 0.000852\n",
      "Train Epoch: 47 [25600/50000 (51%)]\tLosses default: 0.000124 bn: 0.000018 drop: 0.001174 both: 0.002604\n",
      "Train Epoch: 47 [38400/50000 (77%)]\tLosses default: 0.000908 bn: 0.000385 drop: 0.000963 both: 0.000045\n",
      "Train Epoch: 47 [12512/50000 (100%)]\tLosses default: 0.000007 bn: 0.000012 drop: 0.000116 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 0.0882\tAccuracy: 9817.0/10000 (98%)\n",
      "bn: Loss: 0.0810\tAccuracy: 9829.0/10000 (98%)\n",
      "drop: Loss: 0.1083\tAccuracy: 9792.0/10000 (98%)\n",
      "both: Loss: 0.1063\tAccuracy: 9801.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLosses default: 0.000055 bn: 0.000005 drop: 0.000118 both: 0.000030\n",
      "Train Epoch: 48 [12800/50000 (26%)]\tLosses default: 0.000137 bn: 0.000064 drop: 0.000131 both: 0.000269\n",
      "Train Epoch: 48 [25600/50000 (51%)]\tLosses default: 0.000067 bn: 0.040053 drop: 0.000112 both: 0.000030\n",
      "Train Epoch: 48 [38400/50000 (77%)]\tLosses default: 0.000127 bn: 0.000043 drop: 0.000283 both: 0.000267\n",
      "Train Epoch: 48 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000000 both: 0.000181\n",
      "Test set:\n",
      "default: Loss: 0.0871\tAccuracy: 9839.0/10000 (98%)\n",
      "bn: Loss: 0.0842\tAccuracy: 9831.0/10000 (98%)\n",
      "drop: Loss: 0.0963\tAccuracy: 9811.0/10000 (98%)\n",
      "both: Loss: 0.1143\tAccuracy: 9797.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLosses default: 0.000129 bn: 0.000043 drop: 0.004701 both: 0.000010\n",
      "Train Epoch: 49 [12800/50000 (26%)]\tLosses default: 0.000057 bn: 0.000047 drop: 0.000146 both: 0.000015\n",
      "Train Epoch: 49 [25600/50000 (51%)]\tLosses default: 0.000101 bn: 0.001671 drop: 0.000988 both: 0.006539\n",
      "Train Epoch: 49 [38400/50000 (77%)]\tLosses default: 0.000095 bn: 0.000011 drop: 0.006262 both: 0.000422\n",
      "Train Epoch: 49 [12512/50000 (100%)]\tLosses default: 0.000098 bn: 0.000152 drop: 0.016022 both: 0.000209\n",
      "Test set:\n",
      "default: Loss: 0.0876\tAccuracy: 9833.0/10000 (98%)\n",
      "bn: Loss: 0.0855\tAccuracy: 9849.0/10000 (98%)\n",
      "drop: Loss: 0.1013\tAccuracy: 9782.0/10000 (98%)\n",
      "both: Loss: 0.1234\tAccuracy: 9804.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLosses default: 0.000232 bn: 0.000022 drop: 0.030987 both: 0.000060\n",
      "Train Epoch: 50 [12800/50000 (26%)]\tLosses default: 0.000049 bn: 0.000077 drop: 0.010582 both: 0.000041\n",
      "Train Epoch: 50 [25600/50000 (51%)]\tLosses default: 0.000009 bn: 0.002359 drop: 0.000384 both: 0.000009\n",
      "Train Epoch: 50 [38400/50000 (77%)]\tLosses default: 0.001026 bn: 0.001385 drop: 0.004793 both: 0.028789\n",
      "Train Epoch: 50 [12512/50000 (100%)]\tLosses default: 0.000002 bn: 0.225523 drop: 0.000058 both: 0.003517\n",
      "Test set:\n",
      "default: Loss: 0.0871\tAccuracy: 9840.0/10000 (98%)\n",
      "bn: Loss: 0.0845\tAccuracy: 9839.0/10000 (98%)\n",
      "drop: Loss: 0.1028\tAccuracy: 9798.0/10000 (98%)\n",
      "both: Loss: 0.1078\tAccuracy: 9795.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 51 [0/50000 (0%)]\tLosses default: 0.000091 bn: 0.003867 drop: 0.004613 both: 0.001944\n",
      "Train Epoch: 51 [12800/50000 (26%)]\tLosses default: 0.000105 bn: 0.000057 drop: 0.000618 both: 0.000107\n",
      "Train Epoch: 51 [25600/50000 (51%)]\tLosses default: 0.000021 bn: 0.020674 drop: 0.007494 both: 0.000025\n",
      "Train Epoch: 51 [38400/50000 (77%)]\tLosses default: 0.000040 bn: 0.000003 drop: 0.000042 both: 0.000004\n",
      "Train Epoch: 51 [12512/50000 (100%)]\tLosses default: 0.000140 bn: 0.003378 drop: 0.000026 both: 0.001495\n",
      "Test set:\n",
      "default: Loss: 0.0876\tAccuracy: 9839.0/10000 (98%)\n",
      "bn: Loss: 0.0817\tAccuracy: 9831.0/10000 (98%)\n",
      "drop: Loss: 0.1004\tAccuracy: 9812.0/10000 (98%)\n",
      "both: Loss: 0.1154\tAccuracy: 9798.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 52 [0/50000 (0%)]\tLosses default: 0.000113 bn: 0.000822 drop: 0.000354 both: 0.000271\n",
      "Train Epoch: 52 [12800/50000 (26%)]\tLosses default: 0.000029 bn: 0.000013 drop: 0.000211 both: 0.002296\n",
      "Train Epoch: 52 [25600/50000 (51%)]\tLosses default: 0.000023 bn: 0.000041 drop: 0.000015 both: 0.000005\n",
      "Train Epoch: 52 [38400/50000 (77%)]\tLosses default: 0.000024 bn: 0.000242 drop: 0.000254 both: 0.001024\n",
      "Train Epoch: 52 [12512/50000 (100%)]\tLosses default: 0.000005 bn: 0.000010 drop: 0.000062 both: 0.000960\n",
      "Test set:\n",
      "default: Loss: 0.0881\tAccuracy: 9838.0/10000 (98%)\n",
      "bn: Loss: 0.0790\tAccuracy: 9844.0/10000 (98%)\n",
      "drop: Loss: 0.1051\tAccuracy: 9798.0/10000 (98%)\n",
      "both: Loss: 0.1113\tAccuracy: 9804.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 53 [0/50000 (0%)]\tLosses default: 0.000053 bn: 0.000439 drop: 0.004385 both: 0.000132\n",
      "Train Epoch: 53 [12800/50000 (26%)]\tLosses default: 0.000029 bn: 0.000027 drop: 0.039092 both: 0.000309\n",
      "Train Epoch: 53 [25600/50000 (51%)]\tLosses default: 0.000036 bn: 0.000015 drop: 0.001629 both: 0.000174\n",
      "Train Epoch: 53 [38400/50000 (77%)]\tLosses default: 0.000007 bn: 0.000048 drop: 0.000629 both: 0.000073\n",
      "Train Epoch: 53 [12512/50000 (100%)]\tLosses default: 0.000035 bn: 0.000000 drop: 0.000045 both: 0.000000\n",
      "Test set:\n",
      "default: Loss: 0.0884\tAccuracy: 9839.0/10000 (98%)\n",
      "bn: Loss: 0.0818\tAccuracy: 9842.0/10000 (98%)\n",
      "drop: Loss: 0.1035\tAccuracy: 9800.0/10000 (98%)\n",
      "both: Loss: 0.1199\tAccuracy: 9785.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 54 [0/50000 (0%)]\tLosses default: 0.000020 bn: 0.000003 drop: 0.002107 both: 0.000364\n",
      "Train Epoch: 54 [12800/50000 (26%)]\tLosses default: 0.000043 bn: 0.000275 drop: 0.006008 both: 0.000031\n",
      "Train Epoch: 54 [25600/50000 (51%)]\tLosses default: 0.000012 bn: 0.000001 drop: 0.000950 both: 0.000913\n",
      "Train Epoch: 54 [38400/50000 (77%)]\tLosses default: 0.000021 bn: 0.000322 drop: 0.005428 both: 0.000985\n",
      "Train Epoch: 54 [12512/50000 (100%)]\tLosses default: 0.000007 bn: 0.013955 drop: 0.000052 both: 0.000056\n",
      "Test set:\n",
      "default: Loss: 0.0886\tAccuracy: 9834.0/10000 (98%)\n",
      "bn: Loss: 0.0961\tAccuracy: 9820.0/10000 (98%)\n",
      "drop: Loss: 0.0922\tAccuracy: 9822.0/10000 (98%)\n",
      "both: Loss: 0.1075\tAccuracy: 9818.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 55 [0/50000 (0%)]\tLosses default: 0.000027 bn: 0.011477 drop: 0.000601 both: 0.027432\n",
      "Train Epoch: 55 [12800/50000 (26%)]\tLosses default: 0.000008 bn: 0.000004 drop: 0.000053 both: 0.000043\n",
      "Train Epoch: 55 [25600/50000 (51%)]\tLosses default: 0.000032 bn: 0.002175 drop: 0.001792 both: 0.002324\n",
      "Train Epoch: 55 [38400/50000 (77%)]\tLosses default: 0.000005 bn: 0.000023 drop: 0.000099 both: 0.000089\n",
      "Train Epoch: 55 [12512/50000 (100%)]\tLosses default: 0.000002 bn: 0.000019 drop: 0.000003 both: 0.003943\n",
      "Test set:\n",
      "default: Loss: 0.0897\tAccuracy: 9837.0/10000 (98%)\n",
      "bn: Loss: 0.1063\tAccuracy: 9806.0/10000 (98%)\n",
      "drop: Loss: 0.1004\tAccuracy: 9810.0/10000 (98%)\n",
      "both: Loss: 0.1171\tAccuracy: 9799.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 56 [0/50000 (0%)]\tLosses default: 0.000020 bn: 0.000028 drop: 0.000300 both: 0.000074\n",
      "Train Epoch: 56 [12800/50000 (26%)]\tLosses default: 0.000009 bn: 0.000077 drop: 0.000125 both: 0.000407\n",
      "Train Epoch: 56 [25600/50000 (51%)]\tLosses default: 0.000005 bn: 0.000941 drop: 0.000071 both: 0.000045\n",
      "Train Epoch: 56 [38400/50000 (77%)]\tLosses default: 0.000030 bn: 0.000252 drop: 0.000745 both: 0.000174\n",
      "Train Epoch: 56 [12512/50000 (100%)]\tLosses default: 0.000005 bn: 0.173639 drop: 0.000047 both: 0.046405\n",
      "Test set:\n",
      "default: Loss: 0.0906\tAccuracy: 9837.0/10000 (98%)\n",
      "bn: Loss: 0.0866\tAccuracy: 9827.0/10000 (98%)\n",
      "drop: Loss: 0.1015\tAccuracy: 9813.0/10000 (98%)\n",
      "both: Loss: 0.1139\tAccuracy: 9803.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 57 [0/50000 (0%)]\tLosses default: 0.000005 bn: 0.037505 drop: 0.000114 both: 0.001898\n",
      "Train Epoch: 57 [12800/50000 (26%)]\tLosses default: 0.000004 bn: 0.025486 drop: 0.000017 both: 0.000001\n",
      "Train Epoch: 57 [25600/50000 (51%)]\tLosses default: 0.000012 bn: 0.000424 drop: 0.000006 both: 0.000134\n",
      "Train Epoch: 57 [38400/50000 (77%)]\tLosses default: 0.000013 bn: 0.000246 drop: 0.004118 both: 0.000021\n",
      "Train Epoch: 57 [12512/50000 (100%)]\tLosses default: 0.000009 bn: 0.000857 drop: 0.000009 both: 0.103760\n",
      "Test set:\n",
      "default: Loss: 0.0922\tAccuracy: 9842.0/10000 (98%)\n",
      "bn: Loss: 0.0919\tAccuracy: 9824.0/10000 (98%)\n",
      "drop: Loss: 0.0982\tAccuracy: 9811.0/10000 (98%)\n",
      "both: Loss: 0.1112\tAccuracy: 9814.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 58 [0/50000 (0%)]\tLosses default: 0.000014 bn: 0.000027 drop: 0.000070 both: 0.000456\n",
      "Train Epoch: 58 [12800/50000 (26%)]\tLosses default: 0.000008 bn: 0.000017 drop: 0.000293 both: 0.000053\n",
      "Train Epoch: 58 [25600/50000 (51%)]\tLosses default: 0.000009 bn: 0.000019 drop: 0.000135 both: 0.000002\n",
      "Train Epoch: 58 [38400/50000 (77%)]\tLosses default: 0.000015 bn: 0.000004 drop: 0.000043 both: 0.000922\n",
      "Train Epoch: 58 [12512/50000 (100%)]\tLosses default: 0.000009 bn: 0.006151 drop: 0.000003 both: 0.005156\n",
      "Test set:\n",
      "default: Loss: 0.0942\tAccuracy: 9837.0/10000 (98%)\n",
      "bn: Loss: 0.0825\tAccuracy: 9839.0/10000 (98%)\n",
      "drop: Loss: 0.1044\tAccuracy: 9805.0/10000 (98%)\n",
      "both: Loss: 0.1076\tAccuracy: 9824.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 59 [0/50000 (0%)]\tLosses default: 0.000005 bn: 0.000085 drop: 0.000012 both: 0.004518\n",
      "Train Epoch: 59 [12800/50000 (26%)]\tLosses default: 0.000007 bn: 0.000049 drop: 0.000228 both: 0.000120\n",
      "Train Epoch: 59 [25600/50000 (51%)]\tLosses default: 0.000003 bn: 0.000026 drop: 0.000019 both: 0.000027\n",
      "Train Epoch: 59 [38400/50000 (77%)]\tLosses default: 0.000004 bn: 0.000103 drop: 0.000253 both: 0.000012\n",
      "Train Epoch: 59 [12512/50000 (100%)]\tLosses default: 0.003896 bn: 0.000090 drop: 0.000004 both: 0.000216\n",
      "Test set:\n",
      "default: Loss: 0.1768\tAccuracy: 9717.0/10000 (97%)\n",
      "bn: Loss: 0.0925\tAccuracy: 9834.0/10000 (98%)\n",
      "drop: Loss: 0.1014\tAccuracy: 9813.0/10000 (98%)\n",
      "both: Loss: 0.1071\tAccuracy: 9822.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 60 [0/50000 (0%)]\tLosses default: 0.021281 bn: 0.025328 drop: 0.000172 both: 0.006050\n",
      "Train Epoch: 60 [12800/50000 (26%)]\tLosses default: 0.000044 bn: 0.000004 drop: 0.001037 both: 0.000003\n",
      "Train Epoch: 60 [25600/50000 (51%)]\tLosses default: 0.000019 bn: 0.000135 drop: 0.003962 both: 0.000038\n",
      "Train Epoch: 60 [38400/50000 (77%)]\tLosses default: 0.000006 bn: 0.000001 drop: 0.000059 both: 0.000056\n",
      "Train Epoch: 60 [12512/50000 (100%)]\tLosses default: 0.000050 bn: 0.000162 drop: 0.000039 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 0.1068\tAccuracy: 9808.0/10000 (98%)\n",
      "bn: Loss: 0.0942\tAccuracy: 9821.0/10000 (98%)\n",
      "drop: Loss: 0.1131\tAccuracy: 9791.0/10000 (98%)\n",
      "both: Loss: 0.1151\tAccuracy: 9825.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 61 [0/50000 (0%)]\tLosses default: 0.000173 bn: 0.000039 drop: 0.000308 both: 0.000020\n",
      "Train Epoch: 61 [12800/50000 (26%)]\tLosses default: 0.000028 bn: 0.000015 drop: 0.000032 both: 0.079293\n",
      "Train Epoch: 61 [25600/50000 (51%)]\tLosses default: 0.028251 bn: 0.000018 drop: 0.000010 both: 0.000035\n",
      "Train Epoch: 61 [38400/50000 (77%)]\tLosses default: 0.000094 bn: 0.000001 drop: 0.000113 both: 0.000002\n",
      "Train Epoch: 61 [12512/50000 (100%)]\tLosses default: 0.000003 bn: 0.000002 drop: 0.000131 both: 0.000023\n",
      "Test set:\n",
      "default: Loss: 0.0985\tAccuracy: 9829.0/10000 (98%)\n",
      "bn: Loss: 0.0985\tAccuracy: 9825.0/10000 (98%)\n",
      "drop: Loss: 0.0926\tAccuracy: 9821.0/10000 (98%)\n",
      "both: Loss: 0.1149\tAccuracy: 9820.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 62 [0/50000 (0%)]\tLosses default: 0.000022 bn: 0.000058 drop: 0.000087 both: 0.000339\n",
      "Train Epoch: 62 [12800/50000 (26%)]\tLosses default: 0.000021 bn: 0.000002 drop: 0.001399 both: 0.000051\n",
      "Train Epoch: 62 [25600/50000 (51%)]\tLosses default: 0.000111 bn: 0.000003 drop: 0.001311 both: 0.000119\n",
      "Train Epoch: 62 [38400/50000 (77%)]\tLosses default: 0.000030 bn: 0.000152 drop: 0.000133 both: 0.000020\n",
      "Train Epoch: 62 [12512/50000 (100%)]\tLosses default: 0.000004 bn: 0.000004 drop: 0.000002 both: 0.000029\n",
      "Test set:\n",
      "default: Loss: 0.0969\tAccuracy: 9823.0/10000 (98%)\n",
      "bn: Loss: 0.0975\tAccuracy: 9828.0/10000 (98%)\n",
      "drop: Loss: 0.0991\tAccuracy: 9816.0/10000 (98%)\n",
      "both: Loss: 0.1138\tAccuracy: 9813.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 63 [0/50000 (0%)]\tLosses default: 0.000003 bn: 0.016025 drop: 0.000865 both: 0.000001\n",
      "Train Epoch: 63 [12800/50000 (26%)]\tLosses default: 0.000029 bn: 0.002960 drop: 0.000019 both: 0.029717\n",
      "Train Epoch: 63 [25600/50000 (51%)]\tLosses default: 0.000042 bn: 0.000008 drop: 0.000403 both: 0.000002\n",
      "Train Epoch: 63 [38400/50000 (77%)]\tLosses default: 0.000010 bn: 0.000089 drop: 0.000026 both: 0.000008\n",
      "Train Epoch: 63 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.034321 drop: 0.000004 both: 0.131907\n",
      "Test set:\n",
      "default: Loss: 0.0968\tAccuracy: 9829.0/10000 (98%)\n",
      "bn: Loss: 0.0921\tAccuracy: 9828.0/10000 (98%)\n",
      "drop: Loss: 0.0979\tAccuracy: 9813.0/10000 (98%)\n",
      "both: Loss: 0.1143\tAccuracy: 9795.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 64 [0/50000 (0%)]\tLosses default: 0.000130 bn: 0.006722 drop: 0.000141 both: 0.000029\n",
      "Train Epoch: 64 [12800/50000 (26%)]\tLosses default: 0.000051 bn: 0.000159 drop: 0.000013 both: 0.000011\n",
      "Train Epoch: 64 [25600/50000 (51%)]\tLosses default: 0.000004 bn: 0.000001 drop: 0.000013 both: 0.000007\n",
      "Train Epoch: 64 [38400/50000 (77%)]\tLosses default: 0.000006 bn: 0.000069 drop: 0.000049 both: 0.002068\n",
      "Train Epoch: 64 [12512/50000 (100%)]\tLosses default: 0.000058 bn: 0.005151 drop: 0.008783 both: 0.310597\n",
      "Test set:\n",
      "default: Loss: 0.0961\tAccuracy: 9834.0/10000 (98%)\n",
      "bn: Loss: 0.0923\tAccuracy: 9838.0/10000 (98%)\n",
      "drop: Loss: 0.1108\tAccuracy: 9791.0/10000 (98%)\n",
      "both: Loss: 0.1107\tAccuracy: 9821.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 65 [0/50000 (0%)]\tLosses default: 0.000013 bn: 0.000015 drop: 0.014967 both: 0.001021\n",
      "Train Epoch: 65 [12800/50000 (26%)]\tLosses default: 0.000030 bn: 0.000115 drop: 0.000106 both: 0.012531\n",
      "Train Epoch: 65 [25600/50000 (51%)]\tLosses default: 0.000021 bn: 0.000011 drop: 0.000079 both: 0.000085\n",
      "Train Epoch: 65 [38400/50000 (77%)]\tLosses default: 0.000005 bn: 0.000024 drop: 0.000039 both: 0.000002\n",
      "Train Epoch: 65 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.000014 drop: 0.000004 both: 0.000014\n",
      "Test set:\n",
      "default: Loss: 0.0963\tAccuracy: 9832.0/10000 (98%)\n",
      "bn: Loss: 0.0895\tAccuracy: 9839.0/10000 (98%)\n",
      "drop: Loss: 0.1117\tAccuracy: 9799.0/10000 (98%)\n",
      "both: Loss: 0.1133\tAccuracy: 9809.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 66 [0/50000 (0%)]\tLosses default: 0.000028 bn: 0.000003 drop: 0.000015 both: 0.000015\n",
      "Train Epoch: 66 [12800/50000 (26%)]\tLosses default: 0.000025 bn: 0.000003 drop: 0.000004 both: 0.000264\n",
      "Train Epoch: 66 [25600/50000 (51%)]\tLosses default: 0.000001 bn: 0.000146 drop: 0.000011 both: 0.000016\n",
      "Train Epoch: 66 [38400/50000 (77%)]\tLosses default: 0.000013 bn: 0.000022 drop: 0.000019 both: 0.000002\n",
      "Train Epoch: 66 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000001 both: 0.000011\n",
      "Test set:\n",
      "default: Loss: 0.0966\tAccuracy: 9829.0/10000 (98%)\n",
      "bn: Loss: 0.0904\tAccuracy: 9843.0/10000 (98%)\n",
      "drop: Loss: 0.0941\tAccuracy: 9821.0/10000 (98%)\n",
      "both: Loss: 0.1056\tAccuracy: 9830.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 67 [0/50000 (0%)]\tLosses default: 0.000019 bn: 0.000014 drop: 0.000020 both: 0.000049\n",
      "Train Epoch: 67 [12800/50000 (26%)]\tLosses default: 0.000023 bn: 0.001294 drop: 0.000076 both: 0.000053\n",
      "Train Epoch: 67 [25600/50000 (51%)]\tLosses default: 0.000017 bn: 0.000013 drop: 0.000029 both: 0.000071\n",
      "Train Epoch: 67 [38400/50000 (77%)]\tLosses default: 0.000009 bn: 0.001214 drop: 0.000126 both: 0.001095\n",
      "Train Epoch: 67 [12512/50000 (100%)]\tLosses default: 0.000004 bn: 0.010539 drop: 0.000002 both: 0.002354\n",
      "Test set:\n",
      "default: Loss: 0.0968\tAccuracy: 9831.0/10000 (98%)\n",
      "bn: Loss: 0.0929\tAccuracy: 9826.0/10000 (98%)\n",
      "drop: Loss: 0.1178\tAccuracy: 9791.0/10000 (98%)\n",
      "both: Loss: 0.1129\tAccuracy: 9811.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 68 [0/50000 (0%)]\tLosses default: 0.000014 bn: 0.000065 drop: 0.008711 both: 0.000008\n",
      "Train Epoch: 68 [12800/50000 (26%)]\tLosses default: 0.000009 bn: 0.000203 drop: 0.030758 both: 0.000016\n",
      "Train Epoch: 68 [25600/50000 (51%)]\tLosses default: 0.000013 bn: 0.000447 drop: 0.000010 both: 0.001294\n",
      "Train Epoch: 68 [38400/50000 (77%)]\tLosses default: 0.000005 bn: 0.000038 drop: 0.000202 both: 0.000008\n",
      "Train Epoch: 68 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.000421 drop: 0.000171 both: 0.386631\n",
      "Test set:\n",
      "default: Loss: 0.0970\tAccuracy: 9834.0/10000 (98%)\n",
      "bn: Loss: 0.0947\tAccuracy: 9804.0/10000 (98%)\n",
      "drop: Loss: 0.1073\tAccuracy: 9803.0/10000 (98%)\n",
      "both: Loss: 0.1213\tAccuracy: 9800.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 69 [0/50000 (0%)]\tLosses default: 0.000013 bn: 0.000127 drop: 0.000039 both: 0.000040\n",
      "Train Epoch: 69 [12800/50000 (26%)]\tLosses default: 0.000007 bn: 0.000010 drop: 0.001467 both: 0.002215\n",
      "Train Epoch: 69 [25600/50000 (51%)]\tLosses default: 0.000008 bn: 0.000008 drop: 0.000965 both: 0.000004\n",
      "Train Epoch: 69 [38400/50000 (77%)]\tLosses default: 0.000009 bn: 0.000039 drop: 0.000009 both: 0.000005\n",
      "Train Epoch: 69 [12512/50000 (100%)]\tLosses default: 0.000003 bn: 0.000049 drop: 0.000199 both: 0.000135\n",
      "Test set:\n",
      "default: Loss: 0.0976\tAccuracy: 9834.0/10000 (98%)\n",
      "bn: Loss: 0.0923\tAccuracy: 9831.0/10000 (98%)\n",
      "drop: Loss: 0.1029\tAccuracy: 9814.0/10000 (98%)\n",
      "both: Loss: 0.1195\tAccuracy: 9796.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 70 [0/50000 (0%)]\tLosses default: 0.000014 bn: 0.000796 drop: 0.000341 both: 0.000475\n",
      "Train Epoch: 70 [12800/50000 (26%)]\tLosses default: 0.000002 bn: 0.000012 drop: 0.000017 both: 0.000014\n",
      "Train Epoch: 70 [25600/50000 (51%)]\tLosses default: 0.000014 bn: 0.000002 drop: 0.000031 both: 0.000278\n",
      "Train Epoch: 70 [38400/50000 (77%)]\tLosses default: 0.000003 bn: 0.000015 drop: 0.000018 both: 0.000045\n",
      "Train Epoch: 70 [12512/50000 (100%)]\tLosses default: 0.000020 bn: 0.000824 drop: 0.000001 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 0.0987\tAccuracy: 9835.0/10000 (98%)\n",
      "bn: Loss: 0.0861\tAccuracy: 9840.0/10000 (98%)\n",
      "drop: Loss: 0.0991\tAccuracy: 9820.0/10000 (98%)\n",
      "both: Loss: 0.1154\tAccuracy: 9812.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 71 [0/50000 (0%)]\tLosses default: 0.000008 bn: 0.000003 drop: 0.000007 both: 0.000004\n",
      "Train Epoch: 71 [12800/50000 (26%)]\tLosses default: 0.000003 bn: 0.000002 drop: 0.000076 both: 0.000002\n",
      "Train Epoch: 71 [25600/50000 (51%)]\tLosses default: 0.000001 bn: 0.000010 drop: 0.000019 both: 0.000005\n",
      "Train Epoch: 71 [38400/50000 (77%)]\tLosses default: 0.000001 bn: 0.000104 drop: 0.000264 both: 0.000033\n",
      "Train Epoch: 71 [12512/50000 (100%)]\tLosses default: 0.000002 bn: 0.045379 drop: 0.000590 both: 0.000111\n",
      "Test set:\n",
      "default: Loss: 0.0994\tAccuracy: 9838.0/10000 (98%)\n",
      "bn: Loss: 0.0859\tAccuracy: 9838.0/10000 (98%)\n",
      "drop: Loss: 0.1204\tAccuracy: 9769.0/10000 (98%)\n",
      "both: Loss: 0.1185\tAccuracy: 9818.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 72 [0/50000 (0%)]\tLosses default: 0.000003 bn: 0.000053 drop: 0.000059 both: 0.000034\n",
      "Train Epoch: 72 [12800/50000 (26%)]\tLosses default: 0.000002 bn: 0.000005 drop: 0.000038 both: 0.000181\n",
      "Train Epoch: 72 [25600/50000 (51%)]\tLosses default: 0.000003 bn: 0.000002 drop: 0.000050 both: 0.000031\n",
      "Train Epoch: 72 [38400/50000 (77%)]\tLosses default: 0.000004 bn: 0.000006 drop: 0.014522 both: 0.010408\n",
      "Train Epoch: 72 [12512/50000 (100%)]\tLosses default: 0.000004 bn: 0.029796 drop: 0.000054 both: 0.000065\n",
      "Test set:\n",
      "default: Loss: 0.0996\tAccuracy: 9837.0/10000 (98%)\n",
      "bn: Loss: 0.1030\tAccuracy: 9812.0/10000 (98%)\n",
      "drop: Loss: 0.0970\tAccuracy: 9823.0/10000 (98%)\n",
      "both: Loss: 0.1187\tAccuracy: 9804.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 73 [0/50000 (0%)]\tLosses default: 0.000004 bn: 0.000786 drop: 0.000034 both: 0.000111\n",
      "Train Epoch: 73 [12800/50000 (26%)]\tLosses default: 0.000005 bn: 0.000008 drop: 0.002880 both: 0.000024\n",
      "Train Epoch: 73 [25600/50000 (51%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.000015 both: 0.000030\n",
      "Train Epoch: 73 [38400/50000 (77%)]\tLosses default: 0.000005 bn: 0.000269 drop: 0.000001 both: 0.000899\n",
      "Train Epoch: 73 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.015856 drop: 0.000008 both: 0.013408\n",
      "Test set:\n",
      "default: Loss: 0.1001\tAccuracy: 9841.0/10000 (98%)\n",
      "bn: Loss: 0.0926\tAccuracy: 9830.0/10000 (98%)\n",
      "drop: Loss: 0.0971\tAccuracy: 9818.0/10000 (98%)\n",
      "both: Loss: 0.1211\tAccuracy: 9817.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 74 [0/50000 (0%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000021 both: 0.007076\n",
      "Train Epoch: 74 [12800/50000 (26%)]\tLosses default: 0.000002 bn: 0.000025 drop: 0.004598 both: 0.008467\n",
      "Train Epoch: 74 [25600/50000 (51%)]\tLosses default: 0.000001 bn: 0.000110 drop: 0.000028 both: 0.000098\n",
      "Train Epoch: 74 [38400/50000 (77%)]\tLosses default: 0.000001 bn: 0.000027 drop: 0.000252 both: 0.000026\n",
      "Train Epoch: 74 [12512/50000 (100%)]\tLosses default: 0.000003 bn: 0.000652 drop: 0.000185 both: 0.002758\n",
      "Test set:\n",
      "default: Loss: 0.1022\tAccuracy: 9841.0/10000 (98%)\n",
      "bn: Loss: 0.0926\tAccuracy: 9836.0/10000 (98%)\n",
      "drop: Loss: 0.1104\tAccuracy: 9790.0/10000 (98%)\n",
      "both: Loss: 0.1210\tAccuracy: 9811.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 75 [0/50000 (0%)]\tLosses default: 0.000002 bn: 0.000069 drop: 0.000680 both: 0.000002\n",
      "Train Epoch: 75 [12800/50000 (26%)]\tLosses default: 0.000001 bn: 0.000009 drop: 0.000108 both: 0.000001\n",
      "Train Epoch: 75 [25600/50000 (51%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000032 both: 0.004262\n",
      "Train Epoch: 75 [38400/50000 (77%)]\tLosses default: 0.000001 bn: 0.000023 drop: 0.000010 both: 0.000157\n",
      "Train Epoch: 75 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.000017 drop: 0.000114 both: 0.000070\n",
      "Test set:\n",
      "default: Loss: 0.1043\tAccuracy: 9842.0/10000 (98%)\n",
      "bn: Loss: 0.0917\tAccuracy: 9836.0/10000 (98%)\n",
      "drop: Loss: 0.1028\tAccuracy: 9804.0/10000 (98%)\n",
      "both: Loss: 0.1202\tAccuracy: 9805.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 76 [0/50000 (0%)]\tLosses default: 0.000002 bn: 0.000040 drop: 0.000041 both: 0.000090\n",
      "Train Epoch: 76 [12800/50000 (26%)]\tLosses default: 0.000002 bn: 0.000022 drop: 0.000008 both: 0.000001\n",
      "Train Epoch: 76 [25600/50000 (51%)]\tLosses default: 0.000002 bn: 0.000003 drop: 0.057839 both: 0.001662\n",
      "Train Epoch: 76 [38400/50000 (77%)]\tLosses default: 0.000002 bn: 0.000040 drop: 0.000103 both: 0.000004\n",
      "Train Epoch: 76 [12512/50000 (100%)]\tLosses default: 0.000002 bn: 0.000130 drop: 0.000043 both: 0.000009\n",
      "Test set:\n",
      "default: Loss: 0.1041\tAccuracy: 9844.0/10000 (98%)\n",
      "bn: Loss: 0.0882\tAccuracy: 9846.0/10000 (98%)\n",
      "drop: Loss: 0.1168\tAccuracy: 9790.0/10000 (98%)\n",
      "both: Loss: 0.1250\tAccuracy: 9796.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 77 [0/50000 (0%)]\tLosses default: 0.000001 bn: 0.000050 drop: 0.000451 both: 0.000111\n",
      "Train Epoch: 77 [12800/50000 (26%)]\tLosses default: 0.000002 bn: 0.000007 drop: 0.000087 both: 0.000074\n",
      "Train Epoch: 77 [25600/50000 (51%)]\tLosses default: 0.000001 bn: 0.000069 drop: 0.000130 both: 0.000277\n",
      "Train Epoch: 77 [38400/50000 (77%)]\tLosses default: 0.000001 bn: 0.000018 drop: 0.000155 both: 0.000026\n",
      "Train Epoch: 77 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000000 both: 0.000000\n",
      "Test set:\n",
      "default: Loss: 0.1061\tAccuracy: 9843.0/10000 (98%)\n",
      "bn: Loss: 0.0854\tAccuracy: 9837.0/10000 (98%)\n",
      "drop: Loss: 0.1079\tAccuracy: 9816.0/10000 (98%)\n",
      "both: Loss: 0.1167\tAccuracy: 9823.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 78 [0/50000 (0%)]\tLosses default: 0.000002 bn: 0.000013 drop: 0.007494 both: 0.000152\n",
      "Train Epoch: 78 [12800/50000 (26%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000601 both: 0.000002\n",
      "Train Epoch: 78 [25600/50000 (51%)]\tLosses default: 0.000000 bn: 0.000007 drop: 0.000051 both: 0.000224\n",
      "Train Epoch: 78 [38400/50000 (77%)]\tLosses default: 0.000001 bn: 0.000244 drop: 0.011786 both: 0.000289\n",
      "Train Epoch: 78 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.001788 drop: 0.000058 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 0.1082\tAccuracy: 9846.0/10000 (98%)\n",
      "bn: Loss: 0.0985\tAccuracy: 9844.0/10000 (98%)\n",
      "drop: Loss: 0.1159\tAccuracy: 9803.0/10000 (98%)\n",
      "both: Loss: 0.1244\tAccuracy: 9802.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 79 [0/50000 (0%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000145 both: 0.000076\n",
      "Train Epoch: 79 [12800/50000 (26%)]\tLosses default: 0.000419 bn: 0.000007 drop: 0.000020 both: 0.000019\n",
      "Train Epoch: 79 [25600/50000 (51%)]\tLosses default: 0.000207 bn: 0.000065 drop: 0.000067 both: 0.000671\n",
      "Train Epoch: 79 [38400/50000 (77%)]\tLosses default: 0.003195 bn: 0.000278 drop: 0.000763 both: 0.000007\n",
      "Train Epoch: 79 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.000068 drop: 0.000002 both: 0.000185\n",
      "Test set:\n",
      "default: Loss: 0.1151\tAccuracy: 9812.0/10000 (98%)\n",
      "bn: Loss: 0.1023\tAccuracy: 9822.0/10000 (98%)\n",
      "drop: Loss: 0.0995\tAccuracy: 9819.0/10000 (98%)\n",
      "both: Loss: 0.1181\tAccuracy: 9807.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 80 [0/50000 (0%)]\tLosses default: 0.000041 bn: 0.000003 drop: 0.000038 both: 0.000005\n",
      "Train Epoch: 80 [12800/50000 (26%)]\tLosses default: 0.000182 bn: 0.000009 drop: 0.000010 both: 0.000336\n",
      "Train Epoch: 80 [25600/50000 (51%)]\tLosses default: 0.000003 bn: 0.000007 drop: 0.000143 both: 0.000000\n",
      "Train Epoch: 80 [38400/50000 (77%)]\tLosses default: 0.000029 bn: 0.000129 drop: 0.000048 both: 0.000089\n",
      "Train Epoch: 80 [12512/50000 (100%)]\tLosses default: 0.000049 bn: 0.007709 drop: 0.277010 both: 0.006753\n",
      "Test set:\n",
      "default: Loss: 0.1185\tAccuracy: 9814.0/10000 (98%)\n",
      "bn: Loss: 0.0970\tAccuracy: 9841.0/10000 (98%)\n",
      "drop: Loss: 0.1290\tAccuracy: 9780.0/10000 (98%)\n",
      "both: Loss: 0.1246\tAccuracy: 9804.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 81 [0/50000 (0%)]\tLosses default: 0.000832 bn: 0.000004 drop: 0.000055 both: 0.000026\n",
      "Train Epoch: 81 [12800/50000 (26%)]\tLosses default: 0.000013 bn: 0.000680 drop: 0.000740 both: 0.000981\n",
      "Train Epoch: 81 [25600/50000 (51%)]\tLosses default: 0.000038 bn: 0.000017 drop: 0.001528 both: 0.000007\n",
      "Train Epoch: 81 [38400/50000 (77%)]\tLosses default: 0.000022 bn: 0.000049 drop: 0.000212 both: 0.000003\n",
      "Train Epoch: 81 [12512/50000 (100%)]\tLosses default: 0.000005 bn: 0.000293 drop: 0.000045 both: 0.001154\n",
      "Test set:\n",
      "default: Loss: 0.1078\tAccuracy: 9834.0/10000 (98%)\n",
      "bn: Loss: 0.0941\tAccuracy: 9847.0/10000 (98%)\n",
      "drop: Loss: 0.0994\tAccuracy: 9825.0/10000 (98%)\n",
      "both: Loss: 0.1254\tAccuracy: 9808.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 82 [0/50000 (0%)]\tLosses default: 0.000002 bn: 0.000015 drop: 0.000210 both: 0.000017\n",
      "Train Epoch: 82 [12800/50000 (26%)]\tLosses default: 0.000006 bn: 0.000003 drop: 0.000085 both: 0.000004\n",
      "Train Epoch: 82 [25600/50000 (51%)]\tLosses default: 0.000034 bn: 0.000007 drop: 0.000465 both: 0.000070\n",
      "Train Epoch: 82 [38400/50000 (77%)]\tLosses default: 0.000009 bn: 0.000324 drop: 0.000008 both: 0.000010\n",
      "Train Epoch: 82 [12512/50000 (100%)]\tLosses default: 0.000046 bn: 0.000001 drop: 0.000029 both: 0.000000\n",
      "Test set:\n",
      "default: Loss: 0.1060\tAccuracy: 9837.0/10000 (98%)\n",
      "bn: Loss: 0.0957\tAccuracy: 9832.0/10000 (98%)\n",
      "drop: Loss: 0.1034\tAccuracy: 9812.0/10000 (98%)\n",
      "both: Loss: 0.1206\tAccuracy: 9815.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 83 [0/50000 (0%)]\tLosses default: 0.000049 bn: 0.000052 drop: 0.007382 both: 0.000009\n",
      "Train Epoch: 83 [12800/50000 (26%)]\tLosses default: 0.000033 bn: 0.000008 drop: 0.000033 both: 0.000014\n",
      "Train Epoch: 83 [25600/50000 (51%)]\tLosses default: 0.000007 bn: 0.000010 drop: 0.000013 both: 0.000122\n",
      "Train Epoch: 83 [38400/50000 (77%)]\tLosses default: 0.000046 bn: 0.000001 drop: 0.000018 both: 0.001681\n",
      "Train Epoch: 83 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.000109 drop: 0.000001 both: 0.093149\n",
      "Test set:\n",
      "default: Loss: 0.1053\tAccuracy: 9834.0/10000 (98%)\n",
      "bn: Loss: 0.1001\tAccuracy: 9826.0/10000 (98%)\n",
      "drop: Loss: 0.0986\tAccuracy: 9829.0/10000 (98%)\n",
      "both: Loss: 0.1191\tAccuracy: 9822.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 84 [0/50000 (0%)]\tLosses default: 0.000007 bn: 0.000560 drop: 0.000049 both: 0.000038\n",
      "Train Epoch: 84 [12800/50000 (26%)]\tLosses default: 0.000002 bn: 0.003149 drop: 0.000001 both: 0.000042\n",
      "Train Epoch: 84 [25600/50000 (51%)]\tLosses default: 0.000001 bn: 0.000079 drop: 0.000009 both: 0.000308\n",
      "Train Epoch: 84 [38400/50000 (77%)]\tLosses default: 0.000007 bn: 0.000022 drop: 0.000009 both: 0.000612\n",
      "Train Epoch: 84 [12512/50000 (100%)]\tLosses default: 0.000026 bn: 0.099728 drop: 0.000005 both: 0.013134\n",
      "Test set:\n",
      "default: Loss: 0.1053\tAccuracy: 9840.0/10000 (98%)\n",
      "bn: Loss: 0.0909\tAccuracy: 9853.0/10000 (99%)\n",
      "drop: Loss: 0.0997\tAccuracy: 9811.0/10000 (98%)\n",
      "both: Loss: 0.1203\tAccuracy: 9816.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 85 [0/50000 (0%)]\tLosses default: 0.000001 bn: 0.001300 drop: 0.000009 both: 0.000006\n",
      "Train Epoch: 85 [12800/50000 (26%)]\tLosses default: 0.000014 bn: 0.000004 drop: 0.000092 both: 0.000194\n",
      "Train Epoch: 85 [25600/50000 (51%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000022 both: 0.000031\n",
      "Train Epoch: 85 [38400/50000 (77%)]\tLosses default: 0.000004 bn: 0.000074 drop: 0.016798 both: 0.000012\n",
      "Train Epoch: 85 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.000026 drop: 0.000230 both: 0.006814\n",
      "Test set:\n",
      "default: Loss: 0.1046\tAccuracy: 9837.0/10000 (98%)\n",
      "bn: Loss: 0.0955\tAccuracy: 9841.0/10000 (98%)\n",
      "drop: Loss: 0.0988\tAccuracy: 9825.0/10000 (98%)\n",
      "both: Loss: 0.1184\tAccuracy: 9818.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 86 [0/50000 (0%)]\tLosses default: 0.000009 bn: 0.000035 drop: 0.000882 both: 0.000001\n",
      "Train Epoch: 86 [12800/50000 (26%)]\tLosses default: 0.000005 bn: 0.000002 drop: 0.000021 both: 0.000011\n",
      "Train Epoch: 86 [25600/50000 (51%)]\tLosses default: 0.000003 bn: 0.000014 drop: 0.000009 both: 0.000002\n",
      "Train Epoch: 86 [38400/50000 (77%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.001246 both: 0.000000\n",
      "Train Epoch: 86 [12512/50000 (100%)]\tLosses default: 0.000020 bn: 0.000667 drop: 0.000026 both: 0.000130\n",
      "Test set:\n",
      "default: Loss: 0.1044\tAccuracy: 9840.0/10000 (98%)\n",
      "bn: Loss: 0.0914\tAccuracy: 9852.0/10000 (99%)\n",
      "drop: Loss: 0.1056\tAccuracy: 9823.0/10000 (98%)\n",
      "both: Loss: 0.1198\tAccuracy: 9822.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 87 [0/50000 (0%)]\tLosses default: 0.000008 bn: 0.000051 drop: 0.000614 both: 0.000002\n",
      "Train Epoch: 87 [12800/50000 (26%)]\tLosses default: 0.000003 bn: 0.000023 drop: 0.000161 both: 0.000585\n",
      "Train Epoch: 87 [25600/50000 (51%)]\tLosses default: 0.000008 bn: 0.000954 drop: 0.000009 both: 0.000000\n",
      "Train Epoch: 87 [38400/50000 (77%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000005 both: 0.000006\n",
      "Train Epoch: 87 [12512/50000 (100%)]\tLosses default: 0.000003 bn: 0.050870 drop: 0.000054 both: 0.247714\n",
      "Test set:\n",
      "default: Loss: 0.1044\tAccuracy: 9841.0/10000 (98%)\n",
      "bn: Loss: 0.0979\tAccuracy: 9843.0/10000 (98%)\n",
      "drop: Loss: 0.1178\tAccuracy: 9791.0/10000 (98%)\n",
      "both: Loss: 0.1230\tAccuracy: 9806.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 88 [0/50000 (0%)]\tLosses default: 0.000002 bn: 0.000000 drop: 0.000003 both: 0.000029\n",
      "Train Epoch: 88 [12800/50000 (26%)]\tLosses default: 0.000015 bn: 0.000003 drop: 0.000368 both: 0.000523\n",
      "Train Epoch: 88 [25600/50000 (51%)]\tLosses default: 0.000011 bn: 0.004992 drop: 0.000225 both: 0.001446\n",
      "Train Epoch: 88 [38400/50000 (77%)]\tLosses default: 0.000003 bn: 0.000050 drop: 0.000089 both: 0.000053\n",
      "Train Epoch: 88 [12512/50000 (100%)]\tLosses default: 0.000013 bn: 0.000022 drop: 0.000085 both: 0.001397\n",
      "Test set:\n",
      "default: Loss: 0.1046\tAccuracy: 9842.0/10000 (98%)\n",
      "bn: Loss: 0.0972\tAccuracy: 9821.0/10000 (98%)\n",
      "drop: Loss: 0.1102\tAccuracy: 9812.0/10000 (98%)\n",
      "both: Loss: 0.1161\tAccuracy: 9819.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 89 [0/50000 (0%)]\tLosses default: 0.000005 bn: 0.000007 drop: 0.000167 both: 0.000002\n",
      "Train Epoch: 89 [12800/50000 (26%)]\tLosses default: 0.000002 bn: 0.000015 drop: 0.000150 both: 0.000001\n",
      "Train Epoch: 89 [25600/50000 (51%)]\tLosses default: 0.000005 bn: 0.000001 drop: 0.000449 both: 0.000634\n",
      "Train Epoch: 89 [38400/50000 (77%)]\tLosses default: 0.000006 bn: 0.000011 drop: 0.000006 both: 0.000023\n",
      "Train Epoch: 89 [12512/50000 (100%)]\tLosses default: 0.000008 bn: 0.000022 drop: 0.000088 both: 0.000598\n",
      "Test set:\n",
      "default: Loss: 0.1045\tAccuracy: 9848.0/10000 (98%)\n",
      "bn: Loss: 0.0938\tAccuracy: 9853.0/10000 (99%)\n",
      "drop: Loss: 0.1372\tAccuracy: 9779.0/10000 (98%)\n",
      "both: Loss: 0.1174\tAccuracy: 9812.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 90 [0/50000 (0%)]\tLosses default: 0.000005 bn: 0.000000 drop: 0.000543 both: 0.000002\n",
      "Train Epoch: 90 [12800/50000 (26%)]\tLosses default: 0.000002 bn: 0.001003 drop: 0.003024 both: 0.000065\n",
      "Train Epoch: 90 [25600/50000 (51%)]\tLosses default: 0.000000 bn: 0.000140 drop: 0.000003 both: 0.000071\n",
      "Train Epoch: 90 [38400/50000 (77%)]\tLosses default: 0.000001 bn: 0.000009 drop: 0.000007 both: 0.000025\n",
      "Train Epoch: 90 [12512/50000 (100%)]\tLosses default: 0.000015 bn: 0.064801 drop: 0.000093 both: 0.024991\n",
      "Test set:\n",
      "default: Loss: 0.1049\tAccuracy: 9846.0/10000 (98%)\n",
      "bn: Loss: 0.0956\tAccuracy: 9845.0/10000 (98%)\n",
      "drop: Loss: 0.1056\tAccuracy: 9821.0/10000 (98%)\n",
      "both: Loss: 0.1180\tAccuracy: 9817.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 91 [0/50000 (0%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000001 both: 0.000068\n",
      "Train Epoch: 91 [12800/50000 (26%)]\tLosses default: 0.000002 bn: 0.020227 drop: 0.000025 both: 0.000055\n",
      "Train Epoch: 91 [25600/50000 (51%)]\tLosses default: 0.000002 bn: 0.000057 drop: 0.000010 both: 0.000183\n",
      "Train Epoch: 91 [38400/50000 (77%)]\tLosses default: 0.000003 bn: 0.000721 drop: 0.001975 both: 0.000542\n",
      "Train Epoch: 91 [12512/50000 (100%)]\tLosses default: 0.000003 bn: 0.105862 drop: 0.000067 both: 0.228926\n",
      "Test set:\n",
      "default: Loss: 0.1052\tAccuracy: 9846.0/10000 (98%)\n",
      "bn: Loss: 0.1103\tAccuracy: 9827.0/10000 (98%)\n",
      "drop: Loss: 0.1221\tAccuracy: 9807.0/10000 (98%)\n",
      "both: Loss: 0.1287\tAccuracy: 9824.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 92 [0/50000 (0%)]\tLosses default: 0.000001 bn: 0.000160 drop: 0.000016 both: 0.000207\n",
      "Train Epoch: 92 [12800/50000 (26%)]\tLosses default: 0.000001 bn: 0.000053 drop: 0.000065 both: 0.000001\n",
      "Train Epoch: 92 [25600/50000 (51%)]\tLosses default: 0.000001 bn: 0.000008 drop: 0.000012 both: 0.000005\n",
      "Train Epoch: 92 [38400/50000 (77%)]\tLosses default: 0.000005 bn: 0.000030 drop: 0.000908 both: 0.027055\n",
      "Train Epoch: 92 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.000145 drop: 0.000003 both: 0.177926\n",
      "Test set:\n",
      "default: Loss: 0.1058\tAccuracy: 9848.0/10000 (98%)\n",
      "bn: Loss: 0.1134\tAccuracy: 9825.0/10000 (98%)\n",
      "drop: Loss: 0.1069\tAccuracy: 9825.0/10000 (98%)\n",
      "both: Loss: 0.1241\tAccuracy: 9821.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 93 [0/50000 (0%)]\tLosses default: 0.000002 bn: 0.000083 drop: 0.000054 both: 0.000672\n",
      "Train Epoch: 93 [12800/50000 (26%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000091 both: 0.000025\n",
      "Train Epoch: 93 [25600/50000 (51%)]\tLosses default: 0.000005 bn: 0.000386 drop: 0.000052 both: 0.002838\n",
      "Train Epoch: 93 [38400/50000 (77%)]\tLosses default: 0.000004 bn: 0.000032 drop: 0.072565 both: 0.000026\n",
      "Train Epoch: 93 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.000005 drop: 0.000002 both: 0.000008\n",
      "Test set:\n",
      "default: Loss: 0.1063\tAccuracy: 9845.0/10000 (98%)\n",
      "bn: Loss: 0.0975\tAccuracy: 9836.0/10000 (98%)\n",
      "drop: Loss: 0.1121\tAccuracy: 9815.0/10000 (98%)\n",
      "both: Loss: 0.1222\tAccuracy: 9826.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 94 [0/50000 (0%)]\tLosses default: 0.000001 bn: 0.000027 drop: 0.000041 both: 0.000001\n",
      "Train Epoch: 94 [12800/50000 (26%)]\tLosses default: 0.000002 bn: 0.000083 drop: 0.000064 both: 0.000412\n",
      "Train Epoch: 94 [25600/50000 (51%)]\tLosses default: 0.000001 bn: 0.000001 drop: 0.000001 both: 0.000257\n",
      "Train Epoch: 94 [38400/50000 (77%)]\tLosses default: 0.000001 bn: 0.000007 drop: 0.000171 both: 0.000179\n",
      "Train Epoch: 94 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.001018 drop: 0.000001 both: 0.000285\n",
      "Test set:\n",
      "default: Loss: 0.1067\tAccuracy: 9844.0/10000 (98%)\n",
      "bn: Loss: 0.1011\tAccuracy: 9841.0/10000 (98%)\n",
      "drop: Loss: 0.1078\tAccuracy: 9822.0/10000 (98%)\n",
      "both: Loss: 0.1164\tAccuracy: 9835.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 95 [0/50000 (0%)]\tLosses default: 0.000001 bn: 0.000017 drop: 0.000003 both: 0.000004\n",
      "Train Epoch: 95 [12800/50000 (26%)]\tLosses default: 0.000001 bn: 0.000003 drop: 0.000782 both: 0.000006\n",
      "Train Epoch: 95 [25600/50000 (51%)]\tLosses default: 0.000001 bn: 0.000005 drop: 0.000013 both: 0.000023\n",
      "Train Epoch: 95 [38400/50000 (77%)]\tLosses default: 0.000001 bn: 0.000046 drop: 0.009153 both: 0.001901\n",
      "Train Epoch: 95 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.000000 drop: 0.000311 both: 0.000301\n",
      "Test set:\n",
      "default: Loss: 0.1076\tAccuracy: 9844.0/10000 (98%)\n",
      "bn: Loss: 0.0986\tAccuracy: 9843.0/10000 (98%)\n",
      "drop: Loss: 0.1101\tAccuracy: 9813.0/10000 (98%)\n",
      "both: Loss: 0.1233\tAccuracy: 9826.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 96 [0/50000 (0%)]\tLosses default: 0.000000 bn: 0.000067 drop: 0.000022 both: 0.000021\n",
      "Train Epoch: 96 [12800/50000 (26%)]\tLosses default: 0.000001 bn: 0.000067 drop: 0.000063 both: 0.000011\n",
      "Train Epoch: 96 [25600/50000 (51%)]\tLosses default: 0.000000 bn: 0.000028 drop: 0.043468 both: 0.000020\n",
      "Train Epoch: 96 [38400/50000 (77%)]\tLosses default: 0.000000 bn: 0.000837 drop: 0.000007 both: 0.000272\n",
      "Train Epoch: 96 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.008080 drop: 0.000000 both: 0.000979\n",
      "Test set:\n",
      "default: Loss: 0.1096\tAccuracy: 9842.0/10000 (98%)\n",
      "bn: Loss: 0.0952\tAccuracy: 9849.0/10000 (98%)\n",
      "drop: Loss: 0.1182\tAccuracy: 9809.0/10000 (98%)\n",
      "both: Loss: 0.1193\tAccuracy: 9825.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 97 [0/50000 (0%)]\tLosses default: 0.000001 bn: 0.000243 drop: 0.000309 both: 0.000031\n",
      "Train Epoch: 97 [12800/50000 (26%)]\tLosses default: 0.000000 bn: 0.000508 drop: 0.000026 both: 0.000435\n",
      "Train Epoch: 97 [25600/50000 (51%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000037 both: 0.000002\n",
      "Train Epoch: 97 [38400/50000 (77%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000010 both: 0.000096\n",
      "Train Epoch: 97 [12512/50000 (100%)]\tLosses default: 0.000001 bn: 0.003290 drop: 0.000002 both: 0.006637\n",
      "Test set:\n",
      "default: Loss: 0.1106\tAccuracy: 9844.0/10000 (98%)\n",
      "bn: Loss: 0.1022\tAccuracy: 9843.0/10000 (98%)\n",
      "drop: Loss: 0.1044\tAccuracy: 9824.0/10000 (98%)\n",
      "both: Loss: 0.1206\tAccuracy: 9832.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 98 [0/50000 (0%)]\tLosses default: 0.000000 bn: 0.000048 drop: 0.000002 both: 0.000001\n",
      "Train Epoch: 98 [12800/50000 (26%)]\tLosses default: 0.000000 bn: 0.000006 drop: 0.000034 both: 0.000004\n",
      "Train Epoch: 98 [25600/50000 (51%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000002 both: 0.000033\n",
      "Train Epoch: 98 [38400/50000 (77%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000210 both: 0.000045\n",
      "Train Epoch: 98 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.000050 drop: 0.000029 both: 0.323327\n",
      "Test set:\n",
      "default: Loss: 0.1114\tAccuracy: 9846.0/10000 (98%)\n",
      "bn: Loss: 0.1035\tAccuracy: 9837.0/10000 (98%)\n",
      "drop: Loss: 0.1033\tAccuracy: 9818.0/10000 (98%)\n",
      "both: Loss: 0.1222\tAccuracy: 9839.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 99 [0/50000 (0%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000001 both: 0.000002\n",
      "Train Epoch: 99 [12800/50000 (26%)]\tLosses default: 0.000000 bn: 0.000001 drop: 0.000047 both: 0.000011\n",
      "Train Epoch: 99 [25600/50000 (51%)]\tLosses default: 0.000000 bn: 0.000034 drop: 0.000019 both: 0.000075\n",
      "Train Epoch: 99 [38400/50000 (77%)]\tLosses default: 0.000000 bn: 0.000213 drop: 0.000078 both: 0.001638\n",
      "Train Epoch: 99 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.042250 drop: 0.000006 both: 0.000004\n",
      "Test set:\n",
      "default: Loss: 0.1126\tAccuracy: 9838.0/10000 (98%)\n",
      "bn: Loss: 0.1003\tAccuracy: 9847.0/10000 (98%)\n",
      "drop: Loss: 0.1050\tAccuracy: 9824.0/10000 (98%)\n",
      "both: Loss: 0.1236\tAccuracy: 9828.0/10000 (98%)\n",
      "\n",
      "Train Epoch: 100 [0/50000 (0%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000002 both: 0.000029\n",
      "Train Epoch: 100 [12800/50000 (26%)]\tLosses default: 0.000000 bn: 0.000002 drop: 0.000006 both: 0.000000\n",
      "Train Epoch: 100 [25600/50000 (51%)]\tLosses default: 0.000000 bn: 0.000047 drop: 0.000003 both: 0.000002\n",
      "Train Epoch: 100 [38400/50000 (77%)]\tLosses default: 0.000000 bn: 0.000056 drop: 0.000001 both: 0.000001\n",
      "Train Epoch: 100 [12512/50000 (100%)]\tLosses default: 0.000000 bn: 0.000981 drop: 0.000000 both: 0.000000\n",
      "Test set:\n",
      "default: Loss: 0.1148\tAccuracy: 9841.0/10000 (98%)\n",
      "bn: Loss: 0.1037\tAccuracy: 9829.0/10000 (98%)\n",
      "drop: Loss: 0.1315\tAccuracy: 9795.0/10000 (98%)\n",
      "both: Loss: 0.1392\tAccuracy: 9800.0/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    for model in models.values():\n",
    "        model.train()\n",
    "    train(epoch, models)\n",
    "    for model in models.values():\n",
    "        model.eval()\n",
    "    test(models, valid_loader, test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(test_log, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(test_log, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3261975348234177, 90.94)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_log['default'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dacc630174d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/pytorh_test/utils.py\u001b[0m in \u001b[0;36mplot_graphs\u001b[0;34m(log, tpe)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtpe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mhandlers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/pytorh_test/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtpe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mhandlers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "plot_graphs(train_log, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7be189ada001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_log['default'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch15]",
   "language": "python",
   "name": "conda-env-torch15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
